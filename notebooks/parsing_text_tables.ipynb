{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d063411",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3762c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: camelot-py in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: chardet>=3.0.4 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (5.2.0)\n",
      "Requirement already satisfied: click>=6.7 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (8.1.7)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (1.26.4)\n",
      "Requirement already satisfied: openpyxl>=2.5.8 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (3.1.2)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (2.2.2)\n",
      "Requirement already satisfied: pdfminer.six>=20200726 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (20231228)\n",
      "Requirement already satisfied: pypdf>=3.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (4.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from camelot-py) (0.9.0)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from openpyxl>=2.5.8->camelot-py) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pandas>=0.23.4->camelot-py) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pandas>=0.23.4->camelot-py) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pandas>=0.23.4->camelot-py) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pdfminer.six>=20200726->camelot-py) (2.0.12)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pdfminer.six>=20200726->camelot-py) (42.0.5)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pypdf>=3.0.0->camelot-py) (4.11.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py) (1.15.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.23.4->camelot-py) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py) (2.21)\n",
      "Requirement already satisfied: opencv-python in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: tabula-py==2.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from tabula-py==2.9.0) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from tabula-py==2.9.0) (1.26.4)\n",
      "Requirement already satisfied: distro in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from tabula-py==2.9.0) (1.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pandas>=0.25.3->tabula-py==2.9.0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pandas>=0.25.3->tabula-py==2.9.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pandas>=0.25.3->tabula-py==2.9.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py==2.9.0) (1.16.0)\n",
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (0.0.278)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (0.5.14)\n",
      "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
      "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (2.10.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (2.27.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Using cached langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: langsmith\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.49\n",
      "    Uninstalling langsmith-0.1.49:\n",
      "      Successfully uninstalled langsmith-0.1.49\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.1.40 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langsmith-0.0.92\n",
      "Requirement already satisfied: langchain-core==0.1.40 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (0.1.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain-core==0.1.40) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain-core==0.1.40) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core==0.1.40)\n",
      "  Downloading langsmith-0.1.51-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain-core==0.1.40) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain-core==0.1.40) (2.7.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langchain-core==0.1.40) (8.2.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.1.40) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core==0.1.40) (3.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core==0.1.40) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.1.40) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.1.40) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.1.40) (4.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core==0.1.40) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core==0.1.40) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core==0.1.40) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core==0.1.40) (3.7)\n",
      "Downloading langsmith-0.1.51-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/116.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langsmith\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.92\n",
      "    Uninstalling langsmith-0.0.92:\n",
      "      Successfully uninstalled langsmith-0.0.92\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.0.278 requires langsmith<0.1.0,>=0.0.21, but you have langsmith 0.1.51 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langsmith-0.1.51\n",
      "Requirement already satisfied: jpype1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from jpype1) (23.2)\n",
      "Requirement already satisfied: rapidocr-onnxruntime in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (1.3.17)\n",
      "Requirement already satisfied: pyclipper>=1.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (1.3.0.post5)\n",
      "Requirement already satisfied: onnxruntime>=1.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (1.17.3)\n",
      "Requirement already satisfied: opencv-python>=4.5.1.48 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (1.16.0)\n",
      "Requirement already satisfied: Shapely>=1.7.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (2.0.4)\n",
      "Requirement already satisfied: PyYAML in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (6.0)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from rapidocr-onnxruntime) (10.3.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (23.2)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (5.26.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniforge/base/envs/table-parsing/lib/python3.10/site-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install camelot-py\n",
    "!pip install opencv-python\n",
    "!pip install tabula-py==2.9.0\n",
    "!pip install langchain\n",
    "!pip install langchain-core==0.1.40\n",
    "!pip install jpype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "827db47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "import yaml\n",
    "\n",
    "import camelot\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tabula\n",
    "import tiktoken\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import Docx2txtLoader, PyPDFLoader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers.regex import RegexParser\n",
    "from langchain.prompts import (ChatPromptTemplate, HumanMessagePromptTemplate,\n",
    "                               MessagesPlaceholder,\n",
    "                               SystemMessagePromptTemplate)\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a073e8e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "model = \"GPT4\"\n",
    "openai.api_base = os.getenv(\"OPENAI_BASE_GPT4\")\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY_GPT4\")\n",
    "openai.api_version = \"2024-02-15-preview\"\n",
    "openai_api_key = openai.api_key\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"GPT4\",\n",
    "    openai_api_version=\"2024-02-15-preview\",\n",
    "    openai_api_key= openai.api_key,\n",
    "    openai_api_base=openai.api_base,\n",
    "    engine=\"GPT4\",\n",
    "    temperature = 0\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b161270",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd110d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_text_from_file(df, file_path):\n",
    "    file_name = file_path.split(\"/\")[-1]\n",
    "    file_type = file_name.split(\".\")[-1]\n",
    "    if file_type == \"pdf\":\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_type == \"docx\":\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "    text = \"\"\n",
    "    pages = loader.load_and_split()\n",
    "    for page in pages:\n",
    "        text += page.page_content\n",
    "\n",
    "    # Create a new df and concatenate\n",
    "    new_row = pd.DataFrame({\"file\": [file_name], \"text\": [text]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_tables(file_path, pages=\"all\", package=\"tabula\"):\n",
    "    if package == \"camelot\":\n",
    "        # Extract tables with camelot\n",
    "        # flavor could be 'stream' or 'lattice', for documents where tables do not have clear borders, the stream flavor is generally more appropriate.\n",
    "        tables = camelot.read_pdf(file_path, pages=pages, flavor=\"stream\")\n",
    "    else:\n",
    "        tables = tabula.read_pdf(file_path, pages=pages, stream=True, silent=True)\n",
    "\n",
    "    # Convert tables to JSON\n",
    "    tables_json = []\n",
    "    for idx, table in enumerate(tables):\n",
    "\n",
    "        if package == \"camelot\":\n",
    "            page_number = table.parsing_report[\"page\"]\n",
    "            data = table.df.to_json(orient=\"records\")\n",
    "        else:\n",
    "            page_number = \"\"\n",
    "            data = table.to_json(orient=\"records\")\n",
    "\n",
    "        data = {\n",
    "            \"table_number\": idx,\n",
    "            \"page_number\": page_number,\n",
    "            \"data\": data,\n",
    "        }\n",
    "        tables_json.append(data)\n",
    "    return tables_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a52acb",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02815893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = '../data/raw'\n",
    "pathlist = Path(folder_path).glob('*.pdf')\n",
    "filenames = []\n",
    "for file_path in pathlist:\n",
    "    filename = os.path.basename(file_path)\n",
    "    filenames.append(filename)\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac04905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 00:47:15 process GPTsareGPTs.pdf\n",
      "2024-04-28 00:47:15 extract text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPTsareGPTs.pdf</td>\n",
       "      <td>WORKING PAPER\\nGPTs are GPTs: An Early Look at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file                                               text\n",
       "0  GPTsareGPTs.pdf  WORKING PAPER\\nGPTs are GPTs: An Early Look at..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for filename in filenames:\n",
    "    file_path = folder_path + \"/\" + filename\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} process {file_name}\")\n",
    "    # Initialize an empty df\n",
    "    df_file = pd.DataFrame(columns=[\"file\", \"text\"])\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} extract text\")\n",
    "    try:\n",
    "        df_file = extract_text_from_file(df_file, file_path)\n",
    "    except Exception as e:\n",
    "        print(\"----Error: cannot extract text\")\n",
    "        print(f\"----error: {e}\")\n",
    "    df = pd.concat([df, df_file])\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fce1a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 00:55:29 process GPTsareGPTs.pdf\n",
      "2024-04-28 00:55:29 extract text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPTsareGPTs.pdf</td>\n",
       "      <td>WORKING PAPER\\nGPTs are GPTs: An Early Look at...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPTsareGPTs.pdf</td>\n",
       "      <td>WORKING PAPER\\nFigure 1: Taken directly from G...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPTsareGPTs.pdf</td>\n",
       "      <td>WORKING PAPER\\nlevels in GPT-4 responses and b...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPTsareGPTs.pdf</td>\n",
       "      <td>technology. Our evidence supports a wider impa...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPTsareGPTs.pdf</td>\n",
       "      <td>WORKING PAPER\\npolicymakers to predict and reg...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file                                               text  \\\n",
       "0  GPTsareGPTs.pdf  WORKING PAPER\\nGPTs are GPTs: An Early Look at...   \n",
       "1  GPTsareGPTs.pdf  WORKING PAPER\\nFigure 1: Taken directly from G...   \n",
       "2  GPTsareGPTs.pdf  WORKING PAPER\\nlevels in GPT-4 responses and b...   \n",
       "3  GPTsareGPTs.pdf  technology. Our evidence supports a wider impa...   \n",
       "4  GPTsareGPTs.pdf  WORKING PAPER\\npolicymakers to predict and reg...   \n",
       "\n",
       "   page_number  \n",
       "0          1.0  \n",
       "1          2.0  \n",
       "2          3.0  \n",
       "3          4.0  \n",
       "4          5.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def extract_text_from_file(df, file_path):\n",
    "    file_name = file_path.split(\"/\")[-1]\n",
    "    file_type = file_name.split(\".\")[-1]\n",
    "    if file_type == \"pdf\":\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_type == \"docx\":\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "    pages = loader.load_and_split()\n",
    "    for page_number, page in enumerate(pages, start=1):\n",
    "        # Each page's text is added as a new row in the DataFrame\n",
    "        new_row = pd.DataFrame({\n",
    "            \"file\": [file_name],\n",
    "            \"page_number\": [page_number],\n",
    "            \"text\": [page.page_content]\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for filename in filenames:\n",
    "    file_path = folder_path + \"/\" + filename\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} process {file_name}\")\n",
    "    # Initialize an empty df\n",
    "    df_file = pd.DataFrame(columns=[\"file\", \"text\"])\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} extract text\")\n",
    "    try:\n",
    "        df_file = extract_text_from_file(df_file, file_path)\n",
    "    except Exception as e:\n",
    "        print(\"----Error: cannot extract text\")\n",
    "        print(f\"----error: {e}\")\n",
    "    df = pd.concat([df, df_file])\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0768139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw/GPTsareGPTs.pdf'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd0cd354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 10:24:03 process GPTsareGPTs.pdf\n",
      "2024-04-28 10:24:03 extract table\n",
      "2024-04-28 10:24:03 extract table with camelot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 10:24:07 extract table with tabula\n",
      "Source: camelot, Table: {'table_number': 0, 'page_number': 1, 'data': '[{\"0\":\"Abstract\",\"1\":\"\"},{\"0\":\"\",\"1\":\"We investigate the potential implications of large language models (LLMs), such as Generative Pre-\"},{\"0\":\"trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from\",\"1\":\"\"},{\"0\":\"LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based\",\"1\":\"\"},{\"0\":\"\",\"1\":\"on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classi\\\\ufb01cations.\"},{\"0\":\"Our \\\\ufb01ndings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks\",\"1\":\"\"},{\"0\":\"a\\\\ufb00ected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their\",\"1\":\"\"},{\"0\":\"\",\"1\":\"tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs.\"},{\"0\":\"The projected e\\\\ufb00ects span all wage levels, with higher-income jobs potentially facing greater exposure to\",\"1\":\"\"},{\"0\":\"LLM capabilities and LLM-powered software. Signi\\\\ufb01cantly, these impacts are not restricted to industries\",\"1\":\"\"},{\"0\":\"with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15%\",\"1\":\"\"},{\"0\":\"of all worker tasks in the US could be completed signi\\\\ufb01cantly faster at the same level of quality. When\",\"1\":\"\"},{\"0\":\"incorporating software and tooling built on top of LLMs,\",\"1\":\"this share increases to between 47 and 56%\"},{\"0\":\"of all tasks. This \\\\ufb01nding implies that LLM-powered software will have a substantial e\\\\ufb00ect on scaling\",\"1\":\"\"},{\"0\":\"the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of\",\"1\":\"\"},{\"0\":\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\",\"1\":\"\"},{\"0\":\"implications.\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 1, 'page_number': 2, 'data': '[{\"0\":\"\",\"1\":\"Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly\"},{\"0\":\"model capabilities are progressing \\\\u2013 consider the jump in exam performance between GPT-3.5 and GPT-4\",\"1\":\"\"},{\"0\":\"(OpenAI, 2023b).\",\"1\":\"\"},{\"0\":\"\",\"1\":\"Our study is motivated less by the progress of these models alone though, and more by the breadth,\"},{\"0\":\"scale, and capabilities we\\\\u2019ve seen in the complementary technologies developed around them. The role of\",\"1\":\"\"},{\"0\":\"complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\",\"1\":\"\"},{\"0\":\"on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\",\"1\":\"\"},{\"0\":\"discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\",\"1\":\"\"},{\"0\":\"also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\",\"1\":\"\"},{\"0\":\"for custom search applications, and LLMs can perform tasks such as summarization and classi\\\\ufb01cation where\",\"1\":\"\"},{\"0\":\"the context may be largely contained in the prompt.\",\"1\":\"\"},{\"0\":\"\",\"1\":\"To complement predictions of technology\\\\u2019s impacts on work and provide a framework for understanding\"},{\"0\":\"the evolving landscape of\",\"1\":\"language models and their associated technologies, we propose a new rubric\"},{\"0\":\"for assessing LLM capabilities and their potential e\\\\ufb00ects on jobs. This rubric (A.1) measures the overall\",\"1\":\"\"},{\"0\":\"exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\",\"1\":\"\"},{\"0\":\"(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We de\\\\ufb01ne exposure as a proxy for potential\",\"1\":\"\"},{\"0\":\"\",\"1\":\"economic impact without distinguishing between labor-augmenting or labor-displacing e\\\\ufb00ects. We employ\"},{\"0\":\"\",\"1\":\"human annotators and GPT-4 itself as a classi\\\\ufb01er to apply this rubric to occupational data in the U.S. economy,\"},{\"0\":\"primarily sourced from the O*NET database.12\",\"1\":\"\"},{\"0\":\"\",\"1\":\"To construct our primary exposure dataset, we collected both human annotations and GPT-4 classi\\\\ufb01cations,\"},{\"0\":\"using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\",\"1\":\"\"},{\"0\":\"\",\"1\":\"1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\"},{\"0\":\"et al., 2022)\",\"1\":\"\"},{\"0\":\"\",\"1\":\"2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\"},{\"0\":\"motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI\\\\u2019s launch partners\",\"1\":\"\"},{\"0\":\"(OpenAI, 2023b).\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 2, 'page_number': 3, 'data': '[{\"0\":\"WORKING PAPER\"},{\"0\":\"levels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\"},{\"0\":\"This exposure measure re\\\\ufb02ects an estimate of the technical capacity to make human labor more e\\\\ufb03cient;\"},{\"0\":\"however, social, economic,\\\\nregulatory, and other determinants imply that\\\\ntechnical\\\\nfeasibility does not\"},{\"0\":\"guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\"},{\"0\":\"have at least 50% of their tasks exposed when considering both current model capabilities and anticipated\"},{\"0\":\"tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\"},{\"0\":\"exposed to LLMs when considering existing language and code capabilities without additional software or\"},{\"0\":\"modalities. Accounting for other generative models and complementary technologies, our human estimates\"},{\"0\":\"indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\"},{\"0\":\"Our \\\\ufb01ndings consistently show across both human and GPT-4 annotations that most occupations exhibit\"},{\"0\":\"some degree of exposure to LLMs, with varying exposure levels across di\\\\ufb00erent types of work. Occupations\"},{\"0\":\"with higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\"},{\"0\":\"exposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\"},{\"0\":\"using O*NET\\\\u2019s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\"},{\"0\":\"a negative correlation with exposure, while programming and writing skills are positively associated with\"},{\"0\":\"LLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \\\\\"Job Zones\\\\\" and \\\\ufb01nd that\"},{\"0\":\"occupational exposure to LLMs weakly increases with the di\\\\ufb03culty of job preparation.\\\\nIn other words,\"},{\"0\":\"workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\"},{\"0\":\"We further compare our measurements to previous e\\\\ufb00orts documenting the distribution of automation\"},{\"0\":\"exposure in the economy and \\\\ufb01nd broadly consistent results. Most other technology exposure measures we\"},{\"0\":\"examine are statistically signi\\\\ufb01cantly correlated with our preferred exposure measure, while measures of\"},{\"0\":\"manual routineness and robotics exposure show negative correlations. The variance explained by these earlier\"},{\"0\":\"e\\\\ufb00orts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\"},{\"0\":\"Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\"},{\"0\":\"to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\"},{\"0\":\"measurements.\"},{\"0\":\"We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\"},{\"0\":\"exhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure.\\\\nThe\"},{\"0\":\"connection between productivity growth in the past decade and overall LLM exposure appears weak, suggesting\"},{\"0\":\"a potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease\"},{\"0\":\"3\"},{\"0\":\"e\\\\ufb00ects (Baumol, 2012; Aghion et al., 2018).\"},{\"0\":\"Our analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs\"},{\"0\":\"have consistently improved in capabilities over time, their growing economic e\\\\ufb00ect is expected to persist and\"},{\"0\":\"increase even if we halt the development of new capabilities today. We also \\\\ufb01nd that the potential impact of\"},{\"0\":\"LLMs expands signi\\\\ufb01cantly when we take into account the development of complementary technologies.\"},{\"0\":\"Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\"},{\"0\":\"technologies (GPTs).4\\\\n(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\"},{\"0\":\"(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\"},{\"0\":\"technology. Our evidence supports a wider impact, as even subsets of machine learning software meet the\"},{\"0\":\"criteria for general-purpose technology status independently. This paper\\\\u2019s primary contributions are to provide\"},{\"0\":\"a set of measurements of LLM impact potential and to demonstrate the use case of applying LLMs to develop\"},{\"0\":\"such measurements e\\\\ufb03ciently and at scale. Additionally, we showcase the general-purpose potential of LLMs.\"},{\"0\":\"If \\\\\"GPTs are GPTs,\\\\\" the eventual trajectory of LLM development and application may be challenging for\"},{\"0\":\"3Baumol\\\\u2019s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\"},{\"0\":\"increases over time. This happens because wages for skilled workers in other industries increase, but\\\\nthere is no corresponding\"},{\"0\":\"increase in productivity or e\\\\ufb03ciency in these service industries. Therefore, the cost of labor in these industries becomes relatively\"},{\"0\":\"more expensive compared to other goods and services in the economy.\"},{\"0\":\"4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \\\\\"GPTs are GPTs.\\\\\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 3, 'page_number': 4, 'data': '[{\"0\":\"WORKING PAPER\"},{\"0\":\"policymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms\\\\u2019\"},{\"0\":\"potential will emerge across a broad range of economically valuable use cases, including the creation of new\"},{\"0\":\"types of work (Acemoglu and Restrepo, 2018; Autor et al., 2022a). Our research serves to measure what is\"},{\"0\":\"technically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time.\"},{\"0\":\"The paper is structured as follows: Section 2 reviews relevant prior work, Section 3 discusses methods\"},{\"0\":\"and data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to\"},{\"0\":\"earlier e\\\\ufb00orts, Section 6 discusses the results, and Section 7 o\\\\ufb00ers concluding remarks.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 4, 'page_number': 5, 'data': '[{\"0\":\"WORKING PAPER\"},{\"0\":\"Furthermore, a positive feedback loop may emerge as LLMs surpass a speci\\\\ufb01c performance threshold,\"},{\"0\":\"allowing them to assist in building the very tooling that enhances their usefulness and usability across various\"},{\"0\":\"contexts.\\\\nThis could lower\\\\nthe cost and engineering expertise required to create such tools, potentially\"},{\"0\":\"accelerating LLM adoption and integration even further (Chen et al., 2021; Peng et al., 2023). LLMs can also\"},{\"0\":\"become valuable assets in machine learning model development\\\\u2014serving as coding assistants for researchers,\"},{\"0\":\"data labeling services, or synthetic data generators. There is potential for such models to contribute to\"},{\"0\":\"economic decision-making at the task level, for instance, by re\\\\ufb01ning methods for task and sub-task allocation\"},{\"0\":\"between humans and machines (Singla et al., 2015; Shahaf and Horvitz, 2010). As LLMs advance over time\"},{\"0\":\"and better align with user preferences, we can anticipate continuous improvement in performance. However, it\"},{\"0\":\"is essential to recognize that these trends also bring a variety of serious risks.\\\\n(Khlaaf et al., 2022; Weidinger\"},{\"0\":\"et al., 2022; Solaiman et al., 2019)\"},{\"0\":\"2.2\\\\nThe Economic Impacts of Automation Technologies\"},{\"0\":\"A large and growing body of literature addresses the labor market impacts of AI and automation technologies.\"},{\"0\":\"The concept of skill-biased technological change and the task model of automation\\\\u2014often considered\"},{\"0\":\"the standard framework for understanding technology\\\\u2019s\\\\nin\\\\ufb02uence on labor\\\\u2014originated from research\"},{\"0\":\"demonstrating that technological progress raises the demand for skilled workers over unskilled workers (Katz\"},{\"0\":\"and Murphy, 1992). Numerous studies have built upon this concept, exploring the e\\\\ufb00ects of technological\"},{\"0\":\"change and automation on workers within a task-based framework (Autor et al., 2003; Acemoglu and Autor,\"},{\"0\":\"2011b; Acemoglu and Restrepo, 2018). This strand of research has shown that workers involved in routine and\"},{\"0\":\"repetitive tasks are at a higher risk of technology-driven displacement, a phenomenon known as routine-biased\"},{\"0\":\"technological change. More recent studies have distinguished between technology\\\\u2019s task-displacement and\"},{\"0\":\"task-reinstatement e\\\\ufb00ects (where new technology increases the need for a wider array of labor-intensive tasks)\"},{\"0\":\"(Acemoglu and Restrepo, 2018, 2019). Several studies have shown that automation technologies have resulted\"},{\"0\":\"in wage inequality in the US, driven by relative wage declines for workers specializing in routine tasks (Autor\"},{\"0\":\"et al., 2006; Van Reenen, 2011; Acemoglu and Restrepo, 2022b).\"},{\"0\":\"Prior research has employed various approaches to estimate the overlap between AI capabilities and\"},{\"0\":\"the tasks and activities workers undertake in di\\\\ufb00erent occupations. These methods include mapping patent\"},{\"0\":\"descriptions to worker\\\\ntask descriptions (Webb, 2020; Meindl et al., 2021),\\\\nlinking AI capabilities to\"},{\"0\":\"occupational abilities documented in the O*NET database (Felten et al., 2018, 2023), aligning AI\\\\ntask\"},{\"0\":\"benchmark evaluations with worker tasks via cognitive abilities (Tolan et al., 2021),\\\\nlabeling automation\"},{\"0\":\"potential for a subset of US occupations and using machine learning classi\\\\ufb01ers to estimate this potential for\"},{\"0\":\"all other US occupations (Frey and Osborne, 2017), modeling task-level automation and aggregating the\"},{\"0\":\"results to occupation-level insights (Arntz et al., 2017), collecting expert forecasts (Grace et al., 2018), and\"},{\"0\":\"most relevantly to this paper, devising a new rubric to assess worker activities for their suitability for machine\"},{\"0\":\"learning (Brynjolfsson et al., 2018, 2023). Some of these approaches have found exposure to AI technologies\"},{\"0\":\"at the task-level tends to be diversi\\\\ufb01ed within occupation. Considering each job as a bundle of tasks, it would\"},{\"0\":\"be rare to \\\\ufb01nd any occupation for which AI tools could do nearly all of the work.\\\\n(Autor et al., 2022a) \\\\ufb01nds as\"},{\"0\":\"well that automation and augmentation exposures tend to be positively correlated. There is also a growing set\"},{\"0\":\"of studies examining speci\\\\ufb01c economic impacts and opportunities for LLMs (Bommasani et al., 2021; Felten\"},{\"0\":\"et al., 2023; Korinek, 2023; Mollick and Mollick, 2022; Noy and Zhang, 2023; Peng et al., 2023). Alongside\"},{\"0\":\"this work, our measurements help characterize the broader potential relevance of language models to the\"},{\"0\":\"labor market.\"},{\"0\":\"General-purpose technologies (e.g. printing, the steam engine) are characterized by widespread prolifera-\"},{\"0\":\"tion, continuous improvement, and the generation of complementary innovations (Bresnahan and Trajtenberg,\"},{\"0\":\"1995; Lipsey et al., 2005). Their far-reaching consequences, which unfold over decades, are di\\\\ufb03cult\\\\nto\"},{\"0\":\"anticipate, particularly in relation to labor demand (Bessen, 2018; Korinek and Stiglitz, 2018; Acemoglu et al.,\"}]'}\n",
      "Source: camelot, Table: {'table_number': 5, 'page_number': 6, 'data': '[{\"0\":\"WORKING PAPER\"},{\"0\":\"2020; Benzell et al., 2021). The realization of general purpose technologies\\\\u2019 full potential requires extensive\"},{\"0\":\"co-invention (Bresnahan and Trajtenberg, 1995; Bresnahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\"},{\"0\":\"2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\"},{\"0\":\"Bresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\"},{\"0\":\"studies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\"},{\"0\":\"may require redesign to e\\\\ufb00ectively take advantage of novel machine learning advancements (Bresnahan,\"},{\"0\":\"2019; Agrawal et al., 2021; Goldfarb et al., 2023). Appropriately designed systems can yield considerable\"},{\"0\":\"business value and improve \\\\ufb01rm performance (Rock, 2019; Babina et al., 2021; Zolas et al., 2021), with AI\"},{\"0\":\"tools facilitating the discovery process (Cockburn et al., 2018; Cheng et al., 2022). By employing task-level\"},{\"0\":\"information to assess whether LLMs ful\\\\ufb01ll the criteria of a general purpose technology, we seek to merge the\"},{\"0\":\"two perspectives for understanding the technology-labor relationship.\"},{\"0\":\"We attempt to build on these diverse literature streams in several ways. Echoing (Felten et al., 2023), we\"},{\"0\":\"focus our analysis on the impact of LLMs, rather than addressing machine learning or automation technologies\"},{\"0\":\"more broadly. Additionally, we propose a novel method that employs LLMs, speci\\\\ufb01cally GPT-4, to assess tasks\"},{\"0\":\"for exposure and automation potential, thereby bolstering human scoring e\\\\ufb00orts. Subsequently, we aggregate\"},{\"0\":\"our \\\\ufb01ndings to occupations and industries, capturing the overall potential exposure in the contemporary U.S.\"},{\"0\":\"labor market.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 6, 'page_number': 7, 'data': '[{\"0\":\"\",\"1\":\"\",\"2\":\"WORKING PAPER\",\"3\":\"\"},{\"0\":\"Task ID\",\"1\":\"Occupation Title\",\"2\":\"DWAs\",\"3\":\"Task Description\"},{\"0\":\"14675\",\"1\":\"Computer Systems\",\"2\":\"Monitor computer system performance\",\"3\":\"Monitor system operation to detect potential\"},{\"0\":\"\",\"1\":\"Engineers\\\\/Architects\",\"2\":\"to ensure proper operation.\",\"3\":\"problems.\"},{\"0\":\"18310\",\"1\":\"Acute Care Nurses\",\"2\":\"Operate diagnostic or therapeutic\",\"3\":\"Set up, operate, or monitor invasive equipment\"},{\"0\":\"\",\"1\":\"\",\"2\":\"medical instruments or equipment.\",\"3\":\"and devices, such as colostomy or tracheotomy\"},{\"0\":\"\",\"1\":\"\",\"2\":\"Prepare medical supplies or equipment\",\"3\":\"equipment, mechanical ventilators, catheters,\"},{\"0\":\"\",\"1\":\"\",\"2\":\"for use.\",\"3\":\"gastrointestinal tubes, and central lines.\"},{\"0\":\"4668.0\",\"1\":\"Gambling Cage\",\"2\":\"Execute sales or other \\\\ufb01nancial\",\"3\":\"Cash checks and process credit card advances\"},{\"0\":\"\",\"1\":\"Workers\",\"2\":\"transactions.\",\"3\":\"for patrons.\"},{\"0\":\"15709\",\"1\":\"Online Merchants\",\"2\":\"Execute sales or other \\\\ufb01nancial\",\"3\":\"Deliver e-mail con\\\\ufb01rmation of completed\"},{\"0\":\"\",\"1\":\"\",\"2\":\"transactions.\",\"3\":\"transactions and shipment.\"},{\"0\":\"6529\",\"1\":\"Kindergarten\",\"2\":\"\\\\u2013\",\"3\":\"Involve parent volunteers and older students in\"},{\"0\":\"\",\"1\":\"Teachers, Except\",\"2\":\"\",\"3\":\"children\\\\u2019s activities to facilitate involvement in\"},{\"0\":\"\",\"1\":\"Special Education\",\"2\":\"\",\"3\":\"focused, complex play.\"},{\"0\":\"6568\",\"1\":\"Elementary School\",\"2\":\"\\\\u2013\",\"3\":\"Involve parent volunteers and older students in\"},{\"0\":\"\",\"1\":\"Teachers, Except\",\"2\":\"\",\"3\":\"children\\\\u2019s activities to facilitate involvement in\"},{\"0\":\"\",\"1\":\"Special Education\",\"2\":\"\",\"3\":\"focused, complex play.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 7, 'page_number': 7, 'data': '[{\"0\":\"Special Education\",\"1\":\"focused, complex play.\"},{\"0\":\"6568\\\\nElementary School\",\"1\":\"\\\\u2013\\\\nInvolve parent volunteers and older students in\"},{\"0\":\"Teachers, Except\",\"1\":\"children\\\\u2019s activities to facilitate involvement in\"},{\"0\":\"Special Education\",\"1\":\"focused, complex play.\"},{\"0\":\"Table 1: Sample of occupations,\",\"1\":\"tasks, and Detailed Work Activities from the O*NET database. We see\"},{\"0\":\"\",\"1\":\"that aggregating over activities alone is imprecise, as evidenced by the fact that we\\\\u2019d expect Gambling Cage\"},{\"0\":\"Workers to complete the given DWA in person, using some physicality while we\\\\u2019d expect Online Merchants\",\"1\":\"\"},{\"0\":\"to complete the same activity solely with a computer.\",\"1\":\"\"},{\"0\":\"\",\"1\":\"DWA or complete a task by at least 50 percent. Though GPT-4 has vision capabilities OpenAI (2023b) and\"},{\"0\":\"\",\"1\":\"\\\\\"LLM\\\\\" is often used to refer to a much wider range of modalities, vision and image capabilities were only\"},{\"0\":\"\",\"1\":\"included in our de\\\\ufb01nition of LLM-powered software. We provide a summary of our rubric below, while the\"},{\"0\":\"\",\"1\":\"complete rubric can be found in A.1. When we have labels for DWAs, we \\\\ufb01rst aggregate them to the task\"},{\"0\":\"level before aggregating to the occupation level.\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 8, 'page_number': 7, 'data': '[{\"0\":\"Summary of exposure rubric\",\"1\":\"\"},{\"0\":\"No exposure (E0) if:\",\"1\":\"\"},{\"0\":\"\\\\u2022\",\"1\":\"using the described LLM results in no or minimal reduction in the time required to\"},{\"0\":\"\",\"1\":\"complete the activity or task while maintaining equivalent qualitya or\"},{\"0\":\"\\\\u2022\",\"1\":\"using the described LLM results in a decrease in the quality of the activity\\\\/task output.\"},{\"0\":\"Direct exposure (E1) if:\",\"1\":\"\"},{\"0\":\"\\\\u2022\",\"1\":\"using the described LLM via ChatGPT or the OpenAI playground can decrease the time\"},{\"0\":\"\",\"1\":\"required to complete the DWA or task by at least half (50%).\"},{\"0\":\"LLM+ Exposed (E2) if:\",\"1\":\"\"},{\"0\":\"\\\\u2022\",\"1\":\"access to the described LLM alone would not reduce the time required to complete the\"},{\"0\":\"\",\"1\":\"activity\\\\/task by at least half, but\"},{\"0\":\"\\\\u2022\",\"1\":\"additional software could be developed on top of the LLM that could reduce the time it\"},{\"0\":\"\",\"1\":\"takes to complete the speci\\\\ufb01c activity\\\\/task with quality by at least half. Among these\"},{\"0\":\"\",\"1\":\"systems, we count access to image generation systems.b\"}]'}\n",
      "Source: camelot, Table: {'table_number': 9, 'page_number': 8, 'data': '[{\"0\":\"WORKING PAPER\",\"1\":\"\"},{\"0\":\"or task while maintaining consistent quality. We anticipate that adoption will be highest and most immediate\",\"1\":\"\"},{\"0\":\"for applications that realize a considerable increase in productivity. Although this threshold is somewhat\",\"1\":\"\"},{\"0\":\"\",\"1\":\"arbitrary, it was selected for ease of interpretation by annotators. Moreover, regardless of the chosen threshold,\"},{\"0\":\"we guessed that the real-world reduction in task time would likely be slightly or signi\\\\ufb01cantly lower than our\",\"1\":\"\"},{\"0\":\"estimates, leading us to opt for a relatively high threshold.\",\"1\":\"In our own validation labeling, we found that this\"},{\"0\":\"corresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\",\"1\":\"\"},{\"0\":\"nearly the entire task.\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 10, 'page_number': 8, 'data': '[{\"0\":\"corresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},{\"0\":\"nearly the entire task.\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},{\"0\":\"Comparison\",\"1\":\"W\",\"2\":\"Weighting\",\"3\":\"Agreement\",\"4\":\"Pearson\\\\u2019s\"},{\"0\":\"GPT-4, Rubric 1; Human\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"80.8%\",\"4\":\"0.223\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"65.6%\",\"4\":\"0.591\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"82.1%\",\"4\":\"0.654\"},{\"0\":\"GPT-4, Rubric 2; Human\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"81.8%\",\"4\":\"0.221\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"65.6%\",\"4\":\"0.538\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"79.5%\",\"4\":\"0.589\"},{\"0\":\"GPT-4, Rubric 1; GPT-4, Rubric 2\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"91.1%\",\"4\":\"0.611\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"76.0%\",\"4\":\"0.705\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"82.4%\",\"4\":\"0.680\"}]'}\n",
      "Source: camelot, Table: {'table_number': 11, 'page_number': 8, 'data': '[{\"0\":\"We then collected both human and GPT-4-generated annotations using the exposure rubric, which underlie\"},{\"0\":\"the bulk of the analyses in this paper.\"},{\"0\":\"\\\\u2022 Human Ratings: We obtained human annotations by applying the rubric to each O*NET Detailed\"},{\"0\":\"Worker Activity (DWA) and a subset of all O*NET tasks and then aggregated those DWA and task\"},{\"0\":\"scores5 at the task and occupation levels. The authors personally labeled a large sample of tasks and\"},{\"0\":\"DWAs and enlisted experienced human annotators who have reviewed GPT-3, GPT-3.5 and GPT-4\"},{\"0\":\"outputs as part of OpenAI\\\\u2019s alignment work (Ouyang et al., 2022).\"},{\"0\":\"\\\\u2022 GPT-4 Ratings: We administered a similar rubric to an early version of GPT-4 (OpenAI, 2023b) but on\"},{\"0\":\"all task\\\\/occupation pairs rather than DWAs. We made slight modi\\\\ufb01cations to the rubric (which was\"},{\"0\":\"used as a \\\\\"prompt\\\\\" to the model in this case) to enhance agreement with a set of human labels. Full\"},{\"0\":\"agreement rates are given in Table 2.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 12, 'page_number': 9, 'data': '[{\"0\":\"WORKING PAPER\"},{\"0\":\"we refer to V exposure \\\\u2013 meaning all tasks directly exposed via tools like ChatGPT or the OpenAI Playground\"},{\"0\":\"are considered twice as exposed as tasks requiring some complementary innovation.\"},{\"0\":\"3.4\\\\nLimitations of our methodology\"},{\"0\":\"3.4.1\\\\nSubjective human judgments\"},{\"0\":\"A fundamental limitation of our approach lies in the subjectivity of the labeling.\\\\nIn our study, we employ\"},{\"0\":\"annotators who are familiar with LLM capabilities. However,\\\\nthis group is not occupationally diverse,\"},{\"0\":\"potentially leading to biased judgments regarding LLMs\\\\u2019 reliability and e\\\\ufb00ectiveness in performing tasks\"},{\"0\":\"within unfamiliar occupations. We acknowledge that obtaining high-quality labels for each task in an\"},{\"0\":\"occupation requires workers engaged in those occupations or, at a minimum, possessing in-depth knowledge\"},{\"0\":\"of the diverse tasks within those occupations. This represents an important area for future work in validating\"},{\"0\":\"these results.\"},{\"0\":\"3.4.2\\\\nMeasuring LLMs with GPT-4\"},{\"0\":\"Recent\\\\nresearch indicates that GPT-4 serves as an e\\\\ufb00ective discriminator, capable of applying intricate\"},{\"0\":\"taxonomies and responding to changes in wording and emphasis (OpenAI, 2023b). The outcomes of GPT-4\"},{\"0\":\"task classi\\\\ufb01cation are sensitive to alterations in the rubric\\\\u2019s wording, the prompt\\\\u2019s order and composition, the\"},{\"0\":\"presence or absence of speci\\\\ufb01c examples in the rubric, the level of detail provided, and the de\\\\ufb01nitions given\"},{\"0\":\"for key terms.\\\\nIterating on the prompt, based on observed outcomes in a small validation set, can enhance the\"},{\"0\":\"agreement between model outputs and the rubric\\\\u2019s intent. Consequently, there are slight di\\\\ufb00erences between\"},{\"0\":\"the rubric presented to humans and the one used for GPT-4. This decision was made deliberately to guide\"},{\"0\":\"the model towards reasonable labels without excessively in\\\\ufb02uencing human annotators. As a result, we use\"},{\"0\":\"multiple annotation sources, but none should be considered the de\\\\ufb01nitive ground truth relative to the others.\"},{\"0\":\"In this analysis, we present results from human annotators as our primary results. Further improvement and\"},{\"0\":\"innovation in crafting e\\\\ufb00ective rubrics for LLM classi\\\\ufb01cation remains possible. Still, we observe a high\"},{\"0\":\"degree of agreement between human ratings and GPT-4 ratings at the occupation level concerning overall\"},{\"0\":\"exposure to LLM systems (see Table 2, Figure 2).\"},{\"0\":\"3.4.3\\\\nAdditional Weaknesses\"}]'}\n",
      "Source: camelot, Table: {'table_number': 13, 'page_number': 10, 'data': '[{\"0\":\"Figure 2: Human raters (x-axis) and GPT-4 ratings (y-axis) show a high degree of agreement about LLM\"},{\"0\":\"exposure by occupation. We compute occupation-level exposure in these \\\\ufb01gures by averaging the task-level\"},{\"0\":\"exposures under the V method. O*NET designates some tasks as \\\\\"core\\\\\" and others \\\\\"supplemental\\\\\". Core\"},{\"0\":\"tasks are given twice the weight of supplemental tasks, and all weights sum to one. Near the highest levels of\"},{\"0\":\"exposure following the V method of aggregating exposure scores to occupations, GPT-4 ratings tend to be\"},{\"0\":\"lower than Human ratings. We present the raw scatter plot and the binscatter. Near the top end of exposure\"},{\"0\":\"ratings, humans are on average more likely to rate an occupation as exposed.\"},{\"0\":\"\\\\u2022 Forward-looking and subject to change, with some early evidence. Accurately predicting future\"},{\"0\":\"LLM applications remains a signi\\\\ufb01cant challenge, even for experts (OpenAI, 2023b). The discovery of\"},{\"0\":\"new emergent capabilities, changes in human perception biases, and shifts in technological development\"},{\"0\":\"can all a\\\\ufb00ect\\\\nthe accuracy and reliability of predictions regarding the potential\\\\nimpact of LLMs\"},{\"0\":\"on worker\\\\ntasks and the development of LLM-powered software. Our projections are inherently\"},{\"0\":\"forward-looking and based on current trends, evidence, and perceptions of technological possibilities.\"},{\"0\":\"As a result,\\\\nthey may change as new advancements arise in the \\\\ufb01eld. For example, some tasks that\"},{\"0\":\"seem unlikely for LLMs or LLM-powered software to impact today might change with the introduction\"},{\"0\":\"of new model capabilities. Conversely, tasks that appear exposed might face unforeseen challenges\"},{\"0\":\"limiting language model applications.\"},{\"0\":\"\\\\u2022 Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\"},{\"0\":\"few places where humans and the model tended to get \\\\\"stuck\\\\\" in their assessments:\"},{\"0\":\"\\\\u2013 Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\"},{\"0\":\"it to do so would require multiple people to change their habits or expectations (e.g. meetings,\"},{\"0\":\"negotiations),\"},{\"0\":\"\\\\u2013 Tasks or activities where there is currently some regulation or norm that requires or suggests\"},{\"0\":\"human oversight, judgment or empathy (e.g. making decisions, counseling), and\"},{\"0\":\"\\\\u2013 Tasks or activities where there already exists a technology that can reasonably automate the task\"},{\"0\":\"(e.g. making reservations).\"}]'}\n",
      "Source: camelot, Table: {'table_number': 14, 'page_number': 11, 'data': '[{\"0\":\"WORKING PAPER\"},{\"0\":\"LLMs\\\\u2019 potential impact on the labor market is limited since it does not consider total factor productivity or\"},{\"0\":\"capital input potential.\\\\nIn addition to their in\\\\ufb02uence on labor, LLMs may also in\\\\ufb02uence these dimensions.\"},{\"0\":\"At this stage, some general-purpose technology criteria are easier to evaluate than others. Our primary\"},{\"0\":\"focus at\\\\nthis early stage is to test\\\\nthe hypothesis that LLMs have a pervasive in\\\\ufb02uence on the economy,\"},{\"0\":\"similar to the approach taken by (Goldfarb et al., 2023), who analyzed machine learning di\\\\ufb00usion through\"},{\"0\":\"job postings to assess its status as a general-purpose technology.\\\\nInstead of using job postings or studying\"},{\"0\":\"machine learning in general, we employ the task evaluation approach with both human and GPT-4 annotations.\"},{\"0\":\"This analysis may reveal whether the impacts are limited to a speci\\\\ufb01c set of similar tasks or occupations or if\"},{\"0\":\"they will be more widespread.\"},{\"0\":\"Our \\\\ufb01ndings suggest that, based on their task-level capabilities, LLMs have the potential to signi\\\\ufb01cantly\"},{\"0\":\"a\\\\ufb00ect a diverse range of occupations within the U.S. economy, demonstrating a key attribute of general-purpose\"},{\"0\":\"technologies.\\\\nIn the following sections, we discuss results across various roles and wage structures. Additional\"},{\"0\":\"results on the relative exposure of industries within the U.S. economy can be found in Appendix C.\"},{\"0\":\"4.1\\\\nSummary Statistics\"},{\"0\":\"Summary statistics for these measures can be found in Table 3. Both human and GPT-4 annotations indicate\"},{\"0\":\"that average occupation-level U values fall between 0.14 and 0.15, suggesting that, on average, approximately\"},{\"0\":\"15% of tasks within an occupation are directly exposed to LLMs.6 This \\\\ufb01gure increases to over 30% for V\"},{\"0\":\"and surpasses 50% for Z. Coincidentally, human and GPT-4 annotations also tag between 15% and 14% of\"},{\"0\":\"total tasks in the dataset as being exposed to LLMs. Based on the V values, we estimate that 80% of workers\"},{\"0\":\"belong to an occupation with at least 10% of its tasks exposed to LLMs, while 19% of workers are in an\"},{\"0\":\"occupation where over half of its tasks are labeled as exposed.\"},{\"0\":\"We ran one set of analyses using O*NET\\\\u2019s \\\\\"Importance\\\\\" scores but did not \\\\ufb01nd signi\\\\ufb01cant changes to our\"},{\"0\":\"\\\\ufb01ndings. Though we do acknowledge that not weighting relative importance of a task to a given occupation\"},{\"0\":\"yields some curious results (e.g.\\\\nranking Barbers as having reasonably high exposure).\"},{\"0\":\"Although the potential\\\\nfor\\\\ntasks to be a\\\\ufb00ected is vast, LLMs and LLM-powered software must be\"},{\"0\":\"incorporated into broader systems to fully realize this potential.\\\\nAs is common with general-purpose\"},{\"0\":\"technologies, co-invention barriers may initially impede the rapid di\\\\ufb00usion of GPTs into economic applications.\"},{\"0\":\"Furthermore, predicting the need for human oversight\\\\nis challenging, especially for\\\\ntasks where model\"},{\"0\":\"capabilities equal or surpass human levels. While the requirement for human supervision may initially slow\"},{\"0\":\"down the speed at which these systems di\\\\ufb00use through the economy, users of LLMs and LLM-powered\"},{\"0\":\"systems are likely to become increasingly acquainted with the technology over time, particularly in terms of\"},{\"0\":\"understanding when and how to trust its outputs.\"},{\"0\":\"4.2\\\\nWages and Employment\"},{\"0\":\"In Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\"},{\"0\":\"exposure, where the point\\\\u2019s x-axis value represents the share of an occupation\\\\u2019s tasks that are exposed (at\"},{\"0\":\"each level U, V, and Z) and the point\\\\u2019s y-axis value represents the share of all US occupations with that share\"},{\"0\":\"of tasks exposed. For example, human annotators determined that 2.3% of occupations are U50-exposed,\"},{\"0\":\"21.6% are V50-exposed, and 47.3% are Z50-exposed, where the threshold of 50% comes from the x-axis and\"},{\"0\":\"the percentage of occupations comes from the y axis. At any given point on the x-axis, the vertical distance\"},{\"0\":\"between the U and the Z represents the exposure potential attributable to tools and applications beyond direct\"},{\"0\":\"exposure to LLMs. All tasks within an occupation in this \\\\ufb01gure are given equal weight.\"},{\"0\":\"6We compute occupation-level scores for Table 3 assigning double the weight to tasks designated as \\\\\"core\\\\\" by O*NET as tasks\"},{\"0\":\"designated \\\\\"supplemental\\\\\". All tasks weights sum to one within an occupation.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 15, 'page_number': 12, 'data': '[{\"0\":\"\",\"1\":\"\",\"2\":\"WORKING PAPER\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"Occupation Level Exposure\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"Human\",\"2\":\"\",\"3\":\"GPT-4\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"mean\",\"2\":\"std\",\"3\":\"mean\",\"4\":\"std\",\"5\":\"\",\"6\":\"\"},{\"0\":\"U\",\"1\":\"0.14\",\"2\":\"0.14\",\"3\":\"0.14\",\"4\":\"0.16\",\"5\":\"\",\"6\":\"\"},{\"0\":\"V\",\"1\":\"0.30\",\"2\":\"0.21\",\"3\":\"0.34\",\"4\":\"0.22\",\"5\":\"\",\"6\":\"\"},{\"0\":\"Z\",\"1\":\"0.46\",\"2\":\"0.30\",\"3\":\"0.55\",\"4\":\"0.34\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"\",\"2\":\"Task Level Exposure\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"Human\",\"2\":\"\",\"3\":\"GPT-4\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"mean\",\"2\":\"std\",\"3\":\"mean\",\"4\":\"std\",\"5\":\"\",\"6\":\"\"},{\"0\":\"U\",\"1\":\"0.15\",\"2\":\"0.36\",\"3\":\"0.14\",\"4\":\"0.35\",\"5\":\"\",\"6\":\"\"},{\"0\":\"V\",\"1\":\"0.31\",\"2\":\"0.37\",\"3\":\"0.35\",\"4\":\"0.35\",\"5\":\"\",\"6\":\"\"},{\"0\":\"Z\",\"1\":\"0.47\",\"2\":\"0.50\",\"3\":\"0.56\",\"4\":\"0.50\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"Table 3: Summary statistics of our human and model exposure data. Tasks designated as core tasks for an\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"occupation are given twice the weight as those indicated to be supplemental in the O*NET task \\\\ufb01le.\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"Figure 3: Exposure intensity across the economy, displayed in terms of percent of a\\\\ufb00ected occupations. A\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"given data point gives the percent of occupations with exposure below the given threshold. A previous version\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"of this paper had two labels reversed in the chart, \\\\ufb02ipping human and model responses.\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"In this \\\\ufb01gure, all tasks\"},{\"0\":\"within an occupation are given equal weight.\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"Aggregated at the occupation level, human and GPT-4 annotations exhibit qualitative similarities and\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"tend to correlate, as demonstrated in Figure 4. Human annotations estimate marginally lower exposure for\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"high-wage occupations compared to GPT-4 annotations. While there are numerous low-wage occupations\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"with high exposure and high-wage occupations with low exposure, the overall trend in the binscatter plot\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"reveals that higher wages are associated with increased exposure to LLMs.7\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"The potential exposure to LLMs seems to have little correlation with current employment\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"levels.\",\"6\":\"In\"},{\"0\":\"\",\"1\":\"Figure 4, both human and GPT-4 ratings of overall exposure are aggregated to the occupation-level (y-axis)\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"and compared with the log of total employment (x-axis). Neither plot reveals signi\\\\ufb01cant di\\\\ufb00erences in LLM\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"exposure across varying employment levels.\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"},{\"0\":\"\",\"1\":\"7In aggregating tasks to the occupation-level, we assign half the weight to O*NET supplemental tasks as we do for core tasks.\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 16, 'page_number': 13, 'data': '[{\"0\":\"Figure 4: The binscatter plots depict the exposure to language models (LLMs) in various occupations, as\"},{\"0\":\"assessed by both human evaluators and GPT-4.\\\\nThese plots compare the exposure to LLM and partial\"},{\"0\":\"LLM-powered software (V) at the occupation level against the log of total employment within an occupation\"},{\"0\":\"and log of the median annual wage for occupations. While some discrepancies exist, both human and GPT-4\"},{\"0\":\"assessments indicate that higher wage occupations tend to be more exposed to LLMs. Additionally, numerous\"},{\"0\":\"lower wage occupations demonstrate high exposure based on our rubric. Core tasks receive twice the weight of\"},{\"0\":\"supplemental tasks within occupations when calculating average exposure scores. Employment and wage data\"},{\"0\":\"are sourced from the BLS-OES survey conducted in May 2021.\\\\nIn aggregating tasks to the occupation-level,\"},{\"0\":\"we assign half the weight\\\\nto O*NET supplemental\\\\ntasks as we do for core tasks. All weights within an\"},{\"0\":\"occupation sum to one.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 17, 'page_number': 14, 'data': '[{\"0\":\"\",\"1\":\"WORKING PAPER\"},{\"0\":\"4.3\",\"1\":\"Skill Importance\"},{\"0\":\"\",\"1\":\"In this section, we explore the relationship between the importance of a skill for an occupation (as annotated\"},{\"0\":\"\",\"1\":\"in the O*NET dataset) and our exposure measures. First, we use the Basic Skills provided by O*NET (skill\"},{\"0\":\"\",\"1\":\"de\\\\ufb01nitions can be found in Appendix B) and normalize the measure of skill importance for each occupation\"},{\"0\":\"\",\"1\":\"to improve the comprehensibility of the results. Next, we conduct a regression analysis on our exposure\"},{\"0\":\"measures (U, V, Z) to examine the strength of associations between skill importance and exposure.\",\"1\":\"\"},{\"0\":\"\",\"1\":\"Our \\\\ufb01ndings indicate that the importance of science and critical thinking skills are strongly negatively\"},{\"0\":\"\",\"1\":\"associated with exposure, suggesting that occupations requiring these skills are less likely to be impacted\"},{\"0\":\"\",\"1\":\"by current LLMs. Conversely, programming and writing skills show a strong positive association with\"},{\"0\":\"\",\"1\":\"exposure, implying that occupations involving these skills are more susceptible to being in\\\\ufb02uenced by LLMs\"},{\"0\":\"(see Table 5 for detailed results).\",\"1\":\"\"},{\"0\":\"4.4\",\"1\":\"Barriers to Entry\"},{\"0\":\"\",\"1\":\"Next, we examine barriers to entry to better understand if there is di\\\\ufb00erentiation in exposure due to types of\"},{\"0\":\"\",\"1\":\"jobs. One such proxy is an O*NET occupation-level descriptor called the \\\\\"Job Zone.\\\\\" A Job Zone groups\"},{\"0\":\"\",\"1\":\"occupations that are similar in (a) the level of education needed to get a job in the occupation, (b) the amount\"},{\"0\":\"\",\"1\":\"of related experience required to do the work, and (c) the extent of on-the-job training needed to do the work.\"},{\"0\":\"\",\"1\":\"In the O*NET database, there are 5 Job Zones, with Job Zone 1 requiring the least amount of preparation (3\"},{\"0\":\"\",\"1\":\"months) and Job Zone 5 requiring the most extensive amount of preparation, 4 or more years. We observe that\"},{\"0\":\"\",\"1\":\"median income increases monotonically across Job Zones as the level of preparation needed also increases,\"},{\"0\":\"with the median worker in Job Zone 1 earning $30, 230 and the median worker in Job Zone 5 earning $80, 980.\",\"1\":\"\"},{\"0\":\"\",\"1\":\"All of our measures (U, V, and Z) show an identical pattern, that is, exposure increases from Job Zone 1 to\"},{\"0\":\"\",\"1\":\"Job Zone 4, and either remains similar or decreases at Job Zone 5. Similar to Figure 3, in Figure 5, we plot\"},{\"0\":\"\",\"1\":\"the percentage of workers at every threshold of exposure. We \\\\ufb01nd that, on average, the percentage of workers\"},{\"0\":\"\",\"1\":\"in occupations with greater than 50% V exposure in Job Zones 1 through 5 have V at 0.00% (Job Zone 1),\"},{\"0\":\"6.11% (Job Zone 2), 10.57% (Job Zone 3), 34.5% (Job Zone 4), and 26.45% (Job Zone 5), respectively.8\",\"1\":\"\"},{\"0\":\"4.4.1\",\"1\":\"Typical Education Needed for Entry\"},{\"0\":\"\",\"1\":\"Since inclusion in a Job Zone accounts for both the education required\\\\u2014which itself is a proxy for skill\"},{\"0\":\"\",\"1\":\"acquisition\\\\u2014and the preparation required, we seek data to disentangle these variables. We use two variables\"},{\"0\":\"\",\"1\":\"from the Bureau of Labor Statistics\\\\u2019 Occupational data: \\\\\"Typical Education Needed for Entry\\\\\" and \\\\\"On-the-job\"},{\"0\":\"Training Required to Attain Competency\\\\\" in an occupation. By examining these factors, we aim to uncover\",\"1\":\"\"},{\"0\":\"\",\"1\":\"trends with potential implications for the workforce. There are 3,504,000 workers for whom we lack data on\"},{\"0\":\"education and on-the-job training requirements, and they are therefore excluded from the summary tables.\",\"1\":\"\"},{\"0\":\"\",\"1\":\"Our analysis suggests that individuals holding Bachelor\\\\u2019s, Master\\\\u2019s, and professional degrees are more\"},{\"0\":\"\",\"1\":\"exposed to LLMs and LLM-powered software than those without formal educational credentials (see Table 7).\"},{\"0\":\"\",\"1\":\"Interestingly, we also \\\\ufb01nd that individuals with some college education but no degree exhibit a high level of\"},{\"0\":\"\",\"1\":\"exposure to LLMs and LLM-powered software. Upon examining the table displaying barriers to entry, we\"},{\"0\":\"\",\"1\":\"observe that the jobs with the least exposure require the most training, potentially o\\\\ufb00ering a lower payo\\\\ufb00 (in\"},{\"0\":\"\",\"1\":\"terms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\"},{\"0\":\"or only internship\\\\/residency required appear to yield higher income but are more exposed to LLMs.\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 18, 'page_number': 15, 'data': '[{\"0\":\"WORKING PAPER\"},{\"0\":\"Figure 5: V exposure ratings of occupations in the \\\\ufb01ve Job Zones, which are groups of similar occupations\"},{\"0\":\"that are classi\\\\ufb01ed according to the level of education, experience, and on-the-job training needed to perform\"},{\"0\":\"them. All tasks are weighted equally.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 19, 'page_number': 16, 'data': '[{\"0\":\"Writers and Authors\",\"1\":\"82.5\"},{\"0\":\"Interpreters and Translators\",\"1\":\"82.4\"},{\"0\":\"Public Relations Specialists\",\"1\":\"80.6\"},{\"0\":\"Animal Scientists\",\"1\":\"77.8\"},{\"0\":\"Mathematicians\",\"1\":\"100.0\"},{\"0\":\"Tax Preparers\",\"1\":\"100.0\"},{\"0\":\"Financial Quantitative Analysts\",\"1\":\"100.0\"},{\"0\":\"Writers and Authors\",\"1\":\"100.0\"},{\"0\":\"Web and Digital Interface Designers\",\"1\":\"100.0\"},{\"0\":\"Humans labeled 15 occupations as \\\\\"fully exposed.\\\\\"\",\"1\":\"\"},{\"0\":\"Mathematicians\",\"1\":\"100.0\"},{\"0\":\"Correspondence Clerks\",\"1\":\"95.2\"}]'}\n",
      "Source: camelot, Table: {'table_number': 20, 'page_number': 16, 'data': '[{\"0\":\"Group\",\"1\":\"Occupations with highest exposure\",\"2\":\"% Exposure\"},{\"0\":\"Human UUU\",\"1\":\"Interpreters and Translators\",\"2\":\"76.5\"},{\"0\":\"\",\"1\":\"Survey Researchers\",\"2\":\"75.0\"},{\"0\":\"\",\"1\":\"Poets, Lyricists and Creative Writers\",\"2\":\"68.8\"},{\"0\":\"\",\"1\":\"Animal Scientists\",\"2\":\"66.7\"},{\"0\":\"\",\"1\":\"Public Relations Specialists\",\"2\":\"66.7\"},{\"0\":\"Human VVV\",\"1\":\"Survey Researchers\",\"2\":\"84.4\"},{\"0\":\"\",\"1\":\"Writers and Authors\",\"2\":\"82.5\"},{\"0\":\"\",\"1\":\"Interpreters and Translators\",\"2\":\"82.4\"},{\"0\":\"\",\"1\":\"Public Relations Specialists\",\"2\":\"80.6\"},{\"0\":\"\",\"1\":\"Animal Scientists\",\"2\":\"77.8\"},{\"0\":\"Human ZZZ\",\"1\":\"Mathematicians\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Tax Preparers\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Financial Quantitative Analysts\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Writers and Authors\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Web and Digital Interface Designers\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Humans labeled 15 occupations as \\\\\"fully exposed.\\\\\"\",\"2\":\"\"},{\"0\":\"Model UUU\",\"1\":\"Mathematicians\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Correspondence Clerks\",\"2\":\"95.2\"},{\"0\":\"\",\"1\":\"Blockchain Engineers\",\"2\":\"94.1\"},{\"0\":\"\",\"1\":\"Court Reporters and Simultaneous Captioners\",\"2\":\"92.9\"},{\"0\":\"\",\"1\":\"Proofreaders and Copy Markers\",\"2\":\"90.9\"},{\"0\":\"Model VVV\",\"1\":\"Mathematicians\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Blockchain Engineers\",\"2\":\"97.1\"},{\"0\":\"\",\"1\":\"Court Reporters and Simultaneous Captioners\",\"2\":\"96.4\"},{\"0\":\"\",\"1\":\"Proofreaders and Copy Markers\",\"2\":\"95.5\"},{\"0\":\"\",\"1\":\"Correspondence Clerks\",\"2\":\"95.2\"},{\"0\":\"Model ZZZ\",\"1\":\"Accountants and Auditors\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"News Analysts, Reporters, and Journalists\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Legal Secretaries and Administrative Assistants\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Clinical Data Managers\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"Climate Change Policy Analysts\",\"2\":\"100.0\"},{\"0\":\"\",\"1\":\"The model labeled 86 occupations as \\\\\"fully exposed.\\\\\"\",\"2\":\"\"},{\"0\":\"Highest variance\",\"1\":\"Search Marketing Strategists\",\"2\":\"14.5\"},{\"0\":\"\",\"1\":\"Graphic Designers\",\"2\":\"13.4\"},{\"0\":\"\",\"1\":\"Investment Fund Managers\",\"2\":\"13.0\"},{\"0\":\"\",\"1\":\"Financial Managers\",\"2\":\"13.0\"},{\"0\":\"\",\"1\":\"Insurance Appraisers, Auto Damage\",\"2\":\"12.6\"}]'}\n",
      "Source: camelot, Table: {'table_number': 21, 'page_number': 16, 'data': '[{\"0\":\"Graphic Designers\",\"1\":\"13.4\"},{\"0\":\"Investment Fund Managers\",\"1\":\"13.0\"},{\"0\":\"Financial Managers\",\"1\":\"13.0\"},{\"0\":\"Insurance Appraisers, Auto Damage\",\"1\":\"12.6\"},{\"0\":\"Table 4: Occupations with the highest exposure according to each measurement. The \\\\ufb01nal row lists the\",\"1\":\"\"},{\"0\":\"occupations with the highest f2 value,\\\\nindicating that\",\"1\":\"they had the most variability in exposure scores.\"},{\"0\":\"Exposure percentages indicate the share of an occupation\\\\u2019s task that are exposed to GPTs (UUU) or GPT-powered\",\"1\":\"\"},{\"0\":\"software (VVV and ZZZ), where exposure is de\\\\ufb01ned as driving a reduction in time it takes to complete the task by at\",\"1\":\"\"},{\"0\":\"least 50% (see exposure rubric A.1). As such, occupations listed in this table are those where we estimate\",\"1\":\"\"},{\"0\":\"that GPTs and GPT-powered software are able to save workers a signi\\\\ufb01cant amount of time completing a\",\"1\":\"\"},{\"0\":\"large share of their tasks, but it does not necessarily suggest that their tasks can be fully automated by these\",\"1\":\"\"},{\"0\":\"technologies. All tasks are assigned equal weight within an occupation.\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 22, 'page_number': 17, 'data': '[{\"0\":\"Basic Skill\",\"1\":\"U (\\\\nU\",\"2\":\"V\",\"3\":\"\",\"4\":\"Z (\\\\nZ\"},{\"0\":\"\",\"1\":\"std err)\",\"2\":\"\",\"3\":\"(std err)\",\"4\":\"std err)\"},{\"0\":\"\",\"1\":\"\",\"2\":\"All skill importance scores are normalized to be between 0 and 1.\",\"3\":\"\",\"4\":\"\"},{\"0\":\"Constant\",\"1\":\"0.082***\",\"2\":\"\",\"3\":\"-0.112***\",\"4\":\"0.300***\"},{\"0\":\"\",\"1\":\"(0.011)\",\"2\":\"\",\"3\":\"(0.011)\",\"4\":\"(0.057)\"},{\"0\":\"Active Listening\",\"1\":\"0.128**\",\"2\":\"\",\"3\":\"0.214***\",\"4\":\"0.449***\"},{\"0\":\"\",\"1\":\"(0.047)\",\"2\":\"\",\"3\":\"(0.043)\",\"4\":\"(0.027)\"},{\"0\":\"Mathematics\",\"1\":\"-0.127***\",\"2\":\"\",\"3\":\"0.161***\",\"4\":\"0.787***\"},{\"0\":\"\",\"1\":\"(0.026)\",\"2\":\"\",\"3\":\"(0.021)\",\"4\":\"(0.049)\"},{\"0\":\"Reading Comprehension\",\"1\":\"0.153***\",\"2\":\"\",\"3\":\"0.470***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.041)\",\"2\":\"\",\"3\":\"(0.037)\",\"4\":\"(0.017)\"},{\"0\":\"Science\",\"1\":\"-0.114***\",\"2\":\"\",\"3\":\"-0.230***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.014)\",\"2\":\"\",\"3\":\"(0.012)\",\"4\":\"(0.017)\"},{\"0\":\"Speaking\",\"1\":\"-0.028\",\"2\":\"\",\"3\":\"0.133***\",\"4\":\"0.294***\"},{\"0\":\"\",\"1\":\"(0.039)\",\"2\":\"\",\"3\":\"(0.033)\",\"4\":\"(0.042)\"},{\"0\":\"Writing\",\"1\":\"0.368***\",\"2\":\"\",\"3\":\"0.467***\",\"4\":\"0.566***\"},{\"0\":\"\",\"1\":\"(0.042)\",\"2\":\"\",\"3\":\"(0.037)\",\"4\":\"(0.047)\"},{\"0\":\"Active Learning\",\"1\":\"-0.157***\",\"2\":\"\",\"3\":\"-0.065**\",\"4\":\"0.028\"},{\"0\":\"\",\"1\":\"(0.027)\",\"2\":\"\",\"3\":\"(0.024)\",\"4\":\"(0.032)\"},{\"0\":\"Critical Thinking\",\"1\":\"-0.264***\",\"2\":\"\",\"3\":\"-0.196***\",\"4\":\"-0.129**\"},{\"0\":\"\",\"1\":\"(0.036)\",\"2\":\"\",\"3\":\"(0.033)\",\"4\":\"(0.042)\"},{\"0\":\"Learning Strategies\",\"1\":\"-0.072*\",\"2\":\"\",\"3\":\"-0.209***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.028)\",\"2\":\"\",\"3\":\"(0.025)\",\"4\":\"(0.034)\"},{\"0\":\"Monitoring\",\"1\":\"-0.067**\",\"2\":\"\",\"3\":\"-0.149***\",\"4\":\"-0.232***\"},{\"0\":\"\",\"1\":\"(0.023)\",\"2\":\"\",\"3\":\"0.020)\",\"4\":\"(0.026)\"},{\"0\":\"Programming\",\"1\":\"0.637***\",\"2\":\"\",\"3\":\"0.623***\",\"4\":\"0.609***\"},{\"0\":\"\",\"1\":\"(0.030)\",\"2\":\"\",\"3\":\"(0.022)\",\"4\":\"(0.024)\"}]'}\n",
      "Source: camelot, Table: {'table_number': 23, 'page_number': 17, 'data': '[{\"0\":\"in Appendix B. Task ratings within each occupation for exposure have equal weight.\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"Job\",\"1\":\"Preparation\",\"2\":\"Education\",\"3\":\"Example Occupations\",\"4\":\"Median\",\"5\":\"Tot Emp\",\"6\":\"HUUU\",\"7\":\"MUUU\",\"8\":\"HVVV\",\"9\":\"MVVV\",\"10\":\"HZZZ\",\"11\":\"MZZZ\"},{\"0\":\"Zone\",\"1\":\"Required\",\"2\":\"Required\",\"3\":\"\",\"4\":\"Income\",\"5\":\"(000s)\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"1\",\"1\":\"None or little\",\"2\":\"High school\",\"3\":\"Food preparation workers,\",\"4\":\"$30,230\",\"5\":\"13,100\",\"6\":\"0.03\",\"7\":\"0.04\",\"8\":\"0.06\",\"9\":\"0.06\",\"10\":\"0.09\",\"11\":\"0.08\"},{\"0\":\"\",\"1\":\"(0-3 months)\",\"2\":\"diploma or GED\",\"3\":\"dishwashers, \\\\ufb02oor sanders\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"\",\"1\":\"\",\"2\":\"(otional)\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"2\",\"1\":\"Some (3-12\",\"2\":\"High school\",\"3\":\"Orderlies, customer\",\"4\":\"$38,215\",\"5\":\"73,962\",\"6\":\"0.07\",\"7\":\"0.12\",\"8\":\"0.16\",\"9\":\"0.20\",\"10\":\"0.24\",\"11\":\"0.27\"},{\"0\":\"\",\"1\":\"months)\",\"2\":\"diploma\",\"3\":\"service representatives,\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"\",\"1\":\"\",\"2\":\"\",\"3\":\"tellers\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"3\",\"1\":\"Medium (1-2\",\"2\":\"Vocational school,\",\"3\":\"Electricians, barbers,\",\"4\":\"$54,815\",\"5\":\"37,881\",\"6\":\"0.11\",\"7\":\"0.14\",\"8\":\"0.26\",\"9\":\"0.32\",\"10\":\"0.41\",\"11\":\"0.51\"},{\"0\":\"\",\"1\":\"years)\",\"2\":\"on-the-job training,\",\"3\":\"medical assistants\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"\",\"1\":\"\",\"2\":\"or associate\\\\u2019s\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"\",\"1\":\"\",\"2\":\"degree\",\"3\":\"\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"4\",\"1\":\"Considerable\",\"2\":\"Bachelor\\\\u2019s degree\",\"3\":\"Database administrators,\",\"4\":\"$77,345\",\"5\":\"56,833\",\"6\":\"0.23\",\"7\":\"0.18\",\"8\":\"0.47\",\"9\":\"0.51\",\"10\":\"0.71\",\"11\":\"0.85\"},{\"0\":\"\",\"1\":\"(2-4 years)\",\"2\":\"\",\"3\":\"graphic designers, cost\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"\",\"1\":\"\",\"2\":\"\",\"3\":\"estimators\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"},{\"0\":\"5\",\"1\":\"Extensive (4+\",\"2\":\"Master\\\\u2019s degree or\",\"3\":\"Pharmacists, lawyers,\",\"4\":\"$81,980\",\"5\":\"21,221\",\"6\":\"0.23\",\"7\":\"0.13\",\"8\":\"0.43\",\"9\":\"0.45\",\"10\":\"0.63\",\"11\":\"0.76\"},{\"0\":\"\",\"1\":\"years)\",\"2\":\"higher\",\"3\":\"astronomers\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\",\"9\":\"\",\"10\":\"\",\"11\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 24, 'page_number': 18, 'data': '[{\"0\":\"On The Job Training Required\",\"1\":\"Median Income\",\"2\":\"Tot Emp (000s)\",\"3\":\"H UUU\",\"4\":\"M UUU\",\"5\":\"H VVV\",\"6\":\"M VVV\",\"7\":\"H ZZZ\",\"8\":\"M ZZZ\"},{\"0\":\"None\",\"1\":\"$77,440\",\"2\":\"90,776\",\"3\":\"0.20\",\"4\":\"0.16\",\"5\":\"0.42\",\"6\":\"0.46\",\"7\":\"0.63\",\"8\":\"0.76\"},{\"0\":\"Apprenticeship\",\"1\":\"$55,995\",\"2\":\"3,066\",\"3\":\"0.01\",\"4\":\"0.02\",\"5\":\"0.04\",\"6\":\"0.06\",\"7\":\"0.07\",\"8\":\"0.10\"},{\"0\":\"Internship\\\\/residency\",\"1\":\"$77,110\",\"2\":\"3,063\",\"3\":\"0.16\",\"4\":\"0.06\",\"5\":\"0.36\",\"6\":\"0.38\",\"7\":\"0.55\",\"8\":\"0.71\"},{\"0\":\"Short-term on-the-job training\",\"1\":\"$33,370\",\"2\":\"66,234\",\"3\":\"0.11\",\"4\":\"0.15\",\"5\":\"0.21\",\"6\":\"0.25\",\"7\":\"0.32\",\"8\":\"0.34\"},{\"0\":\"Moderate-term on-the-job training\",\"1\":\"$46,880\",\"2\":\"31,285\",\"3\":\"0.09\",\"4\":\"0.12\",\"5\":\"0.21\",\"6\":\"0.25\",\"7\":\"0.32\",\"8\":\"0.38\"},{\"0\":\"Long-term on-the-job training\",\"1\":\"$48,925\",\"2\":\"5,070\",\"3\":\"0.08\",\"4\":\"0.10\",\"5\":\"0.18\",\"6\":\"0.22\",\"7\":\"0.28\",\"8\":\"0.33\"}]'}\n",
      "Source: camelot, Table: {'table_number': 25, 'page_number': 19, 'data': '[{\"0\":\"5.1\",\"1\":\"Comparison to Earlier E\\\\ufb00orts\"},{\"0\":\"This paper aims to build on a number of previous empirical studies examining the occupational exposure to\",\"1\":\"\"},{\"0\":\"advances in AI and\\\\/or automation. Previous studies have used a variety of methods, including:\",\"1\":\"\"},{\"0\":\"\",\"1\":\"\\\\u2022 Using occupational\\\\ntaxonomies\\\\nlike O*NET to characterize which occupations have routine vs.\"},{\"0\":\"\",\"1\":\"non-routine and manual vs. cognitive task content (Autor et al., 2003; Acemoglu and Autor, 2011a).\"},{\"0\":\"\",\"1\":\"\\\\u2022 Mapping text descriptions of tasks to descriptions of technological advances in patents.\\\\n(Kogan et al.,\"},{\"0\":\"\",\"1\":\"2021; Webb, 2020)\"},{\"0\":\"\",\"1\":\"\\\\u2022 Linking capabilities of AI systems to occupational abilities and aggregating exposure estimates to the\"},{\"0\":\"\",\"1\":\"occupations where those abilities are required.\\\\n(Felten et al., 2018, 2023)\"},{\"0\":\"\",\"1\":\"\\\\u2022 Mapping the results of AI task benchmark evaluations (ImageNet, Robocup, etc.)\\\\nto 59 worker tasks\"},{\"0\":\"\",\"1\":\"through a set of 14 cognitive abilities drawn from the cognitive science literature.\\\\n(Tolan et al., 2021)\"},{\"0\":\"\",\"1\":\"\\\\u2022 Expert\\\\nlabeling of automation potential\\\\nfor a set of O*NET occupations where experts had high\"},{\"0\":\"\",\"1\":\"con\\\\ufb01dence, combined with a probabilistic classi\\\\ufb01er to estimate automation potential for the remainder\"},{\"0\":\"\",\"1\":\"of O*NET occupations.\\\\n(Frey and Osborne, 2017)\"},{\"0\":\"\",\"1\":\"\\\\u2022 Developing a rubric for evaluating the \\\\\"suitability for machine learning\\\\\" (SML) of activities that\"},{\"0\":\"\",\"1\":\"workers are completing in the economy (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018,\"}]'}\n",
      "Source: camelot, Table: {'table_number': 26, 'page_number': 20, 'data': '[{\"0\":\"\",\"1\":\"\",\"2\":\"\",\"3\":\"WORKING PAPER\",\"4\":\"\",\"5\":\"\",\"6\":\"\",\"7\":\"\",\"8\":\"\"},{\"0\":\"\",\"1\":\"Min\",\"2\":\"25th Perc.\",\"3\":\"Median\",\"4\":\"75th Perc\",\"5\":\"Max\",\"6\":\"Mean\",\"7\":\"Std. Dev.\",\"8\":\"Count\"},{\"0\":\"GPT-4 Exposure Rating 1\",\"1\":\"0.00\",\"2\":\"0.13\",\"3\":\"0.34\",\"4\":\"0.50\",\"5\":\"1.00\",\"6\":\"0.33\",\"7\":\"0.22\",\"8\":\"750\"},{\"0\":\"GPT-4 Exposure Rating 2\",\"1\":\"0.00\",\"2\":\"0.09\",\"3\":\"0.24\",\"4\":\"0.40\",\"5\":\"0.98\",\"6\":\"0.26\",\"7\":\"0.20\",\"8\":\"750\"},{\"0\":\"Human Exposure Rating\",\"1\":\"0.00\",\"2\":\"0.09\",\"3\":\"0.29\",\"4\":\"0.47\",\"5\":\"0.84\",\"6\":\"0.29\",\"7\":\"0.21\",\"8\":\"750\"},{\"0\":\"Software (Webb)\",\"1\":\"1.00\",\"2\":\"25.00\",\"3\":\"50.00\",\"4\":\"75.00\",\"5\":\"100.00\",\"6\":\"50.69\",\"7\":\"30.05\",\"8\":\"750\"},{\"0\":\"Robot (Webb)\",\"1\":\"1.00\",\"2\":\"22.00\",\"3\":\"52.00\",\"4\":\"69.00\",\"5\":\"100.00\",\"6\":\"48.61\",\"7\":\"28.61\",\"8\":\"750\"},{\"0\":\"AI (Webb)\",\"1\":\"1.00\",\"2\":\"28.00\",\"3\":\"55.00\",\"4\":\"82.00\",\"5\":\"100.00\",\"6\":\"54.53\",\"7\":\"29.65\",\"8\":\"750\"},{\"0\":\"Suitability for Machine Learning\",\"1\":\"2.60\",\"2\":\"2.84\",\"3\":\"2.95\",\"4\":\"3.12\",\"5\":\"3.55\",\"6\":\"2.99\",\"7\":\"0.18\",\"8\":\"750\"},{\"0\":\"Normalized Routine Cognitive\",\"1\":\"-3.05\",\"2\":\"-0.46\",\"3\":\"0.10\",\"4\":\"0.63\",\"5\":\"3.42\",\"6\":\"0.07\",\"7\":\"0.86\",\"8\":\"750\"},{\"0\":\"Normalized Routine Manual\",\"1\":\"-1.81\",\"2\":\"-0.81\",\"3\":\"-0.11\",\"4\":\"0.73\",\"5\":\"2.96\",\"6\":\"0.05\",\"7\":\"1.01\",\"8\":\"750\"},{\"0\":\"AI Occupational Exposure Score\",\"1\":\"1.42\",\"2\":\"3.09\",\"3\":\"3.56\",\"4\":\"4.04\",\"5\":\"6.54\",\"6\":\"3.56\",\"7\":\"0.70\",\"8\":\"750\"},{\"0\":\"Frey & Osborne Automation\",\"1\":\"0.00\",\"2\":\"0.07\",\"3\":\"0.59\",\"4\":\"0.88\",\"5\":\"0.99\",\"6\":\"0.50\",\"7\":\"0.38\",\"8\":\"681\"},{\"0\":\"Log Avg. Salary\",\"1\":\"10.13\",\"2\":\"10.67\",\"3\":\"11.00\",\"4\":\"11.34\",\"5\":\"12.65\",\"6\":\"11.02\",\"7\":\"0.45\",\"8\":\"749\"}]'}\n",
      "Source: camelot, Table: {'table_number': 27, 'page_number': 21, 'data': '[{\"0\":\"\",\"1\":\"GPT-4 Exposure Rating 1\",\"2\":\"\",\"3\":\"GPT-4 Exposure Rating 2\",\"4\":\"\",\"5\":\"\",\"6\":\"Human Exposure Rating\",\"7\":\"\"},{\"0\":\"(1)\",\"1\":\"(2)\",\"2\":\"\",\"3\":\"(3)\",\"4\":\"(4)\",\"5\":\"\",\"6\":\"(5)\",\"7\":\"(6)\"},{\"0\":\"Software (Webb)\\\\n0.00113\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"0.00123\\\\u21e4\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.00111\\\\u21e4\\\\u21e4\\\\u21e4\",\"4\":\"0.00119\\\\u21e4\\\\u21e4\\\\u21e4\",\"5\":\"\",\"6\":\"0.00096\\\\u21e4\\\\u21e4\\\\u21e4\",\"7\":\"0.00101\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"0\":\"0.00031\",\"1\":\"0.00031\",\"2\":\"\",\"3\":\"0.00031\",\"4\":\"0.00031\",\"5\":\"\",\"6\":\"0.00031\",\"7\":\"0.00031\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"Robot (Webb)\\\\n0.00378\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"0.00405\\\\u21e4\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.00377\\\\u21e4\\\\u21e4\\\\u21e4\",\"4\":\"0.00399\\\\u21e4\\\\u21e4\\\\u21e4\",\"5\":\"\",\"6\":\"0.00371\\\\u21e4\\\\u21e4\\\\u21e4\",\"7\":\"0.00383\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"0\":\"\\\\u0000\",\"1\":\"\\\\u0000\",\"2\":\"\",\"3\":\"\\\\u0000\",\"4\":\"\\\\u0000\",\"5\":\"\",\"6\":\"\\\\u0000\",\"7\":\"\\\\u0000\"},{\"0\":\"0.00032\",\"1\":\"0.00031\",\"2\":\"\",\"3\":\"0.00034\",\"4\":\"0.00033\",\"5\":\"\",\"6\":\"0.00029\",\"7\":\"0.00028\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"AI (Webb)\\\\n0.00080\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"0.00090\\\\u21e4\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.00036\",\"4\":\"0.00045\",\"5\":\"\",\"6\":\"0.00067\\\\u21e4\\\\u21e4\",\"7\":\"0.00071\\\\u21e4\\\\u21e4\"},{\"0\":\"0.00030\",\"1\":\"0.00029\",\"2\":\"\",\"3\":\"0.00030\",\"4\":\"0.00030\",\"5\":\"\",\"6\":\"0.00030\",\"7\":\"0.00030\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"Suitability for Machine Learning\\\\n0.29522\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"0.26888\\\\u21e4\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.28468\\\\u21e4\\\\u21e4\\\\u21e4\",\"4\":\"0.26245\\\\u21e4\\\\u21e4\\\\u21e4\",\"5\":\"\",\"6\":\"0.19514\\\\u21e4\\\\u21e4\\\\u21e4\",\"7\":\"0.18373\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"0\":\"0.04503\",\"1\":\"0.04418\",\"2\":\"\",\"3\":\"0.04404\",\"4\":\"0.04342\",\"5\":\"\",\"6\":\"0.03990\",\"7\":\"0.03886\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"Normalized Routine Cognitive\\\\n0.06601\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"0.06868\\\\u21e4\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.04743\\\\u21e4\\\\u21e4\\\\u21e4\",\"4\":\"0.05015\\\\u21e4\\\\u21e4\\\\u21e4\",\"5\":\"\",\"6\":\"0.03568\\\\u21e4\\\\u21e4\\\\u21e4\",\"7\":\"0.03659\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"0\":\"0.00886\",\"1\":\"0.00894\",\"2\":\"\",\"3\":\"0.00872\",\"4\":\"0.00879\",\"5\":\"\",\"6\":\"0.00671\",\"7\":\"0.00669\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"Normalized Routine Manual\\\\n0.11147\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"0.11371\\\\u21e4\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.09390\\\\u21e4\\\\u21e4\\\\u21e4\",\"4\":\"0.09561\\\\u21e4\\\\u21e4\\\\u21e4\",\"5\":\"\",\"6\":\"0.11045\\\\u21e4\\\\u21e4\\\\u21e4\",\"7\":\"0.11152\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"0\":\"\\\\u0000\",\"1\":\"\\\\u0000\",\"2\":\"\",\"3\":\"\\\\u0000\",\"4\":\"\\\\u0000\",\"5\":\"\",\"6\":\"\\\\u0000\",\"7\":\"\\\\u0000\"},{\"0\":\"0.00785\",\"1\":\"0.00789\",\"2\":\"\",\"3\":\"0.00817\",\"4\":\"0.00818\",\"5\":\"\",\"6\":\"0.00741\",\"7\":\"0.00744\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"AI Occupational Exposure Score\\\\n0.00993\",\"1\":\"0.02465\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.01537\",\"4\":\"0.00265\",\"5\":\"\",\"6\":\"0.00630\",\"7\":\"0.01252\"},{\"0\":\"\",\"1\":\"\",\"2\":\"\",\"3\":\"\\\\u0000\",\"4\":\"\\\\u0000\",\"5\":\"\",\"6\":\"\",\"7\":\"\"},{\"0\":\"0.01107\",\"1\":\"0.01059\",\"2\":\"\",\"3\":\"0.01160\",\"4\":\"0.01114\",\"5\":\"\",\"6\":\"0.00918\",\"7\":\"0.00845\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"Frey & Osborne Automation\\\\n0.03024\\\\u21e4\",\"1\":\"0.03950\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.00364\",\"4\":\"0.01217\",\"5\":\"\",\"6\":\"0.03890\\\\u21e4\\\\u21e4\",\"7\":\"0.04253\\\\u21e4\\\\u21e4\"},{\"0\":\"\\\\u0000\",\"1\":\"\\\\u0000\",\"2\":\"\",\"3\":\"\\\\u0000\",\"4\":\"\\\\u0000\",\"5\":\"\",\"6\":\"\\\\u0000\",\"7\":\"\\\\u0000\"},{\"0\":\"0.01835\",\"1\":\"0.01841\",\"2\":\"\",\"3\":\"0.02007\",\"4\":\"0.01972\",\"5\":\"\",\"6\":\"0.01883\",\"7\":\"0.01858\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"Log Avg. Salary\\\\n0.05804\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"\",\"2\":\"\",\"3\":\"0.04863\\\\u21e4\\\\u21e4\\\\u21e4\",\"4\":\"\",\"5\":\"\",\"6\":\"0.02531\",\"7\":\"\"},{\"0\":\"0.01870\",\"1\":\"\",\"2\":\"\",\"3\":\"0.01860\",\"4\":\"\",\"5\":\"\",\"6\":\"0.01727\",\"7\":\"\"},{\"0\":\"(\\\\n)\",\"1\":\"\",\"2\":\"\",\"3\":\"(\\\\n)\",\"4\":\"\",\"5\":\"\",\"6\":\"(\\\\n)\",\"7\":\"\"},{\"0\":\"Constant\\\\n1.12937\\\\u21e4\\\\u21e4\\\\u21e4\",\"1\":\"0.45743\\\\u21e4\\\\u21e4\\\\u21e4\",\"2\":\"\",\"3\":\"0.96117\\\\u21e4\\\\u21e4\\\\u21e4\",\"4\":\"0.39935\\\\u21e4\\\\u21e4\\\\u21e4\",\"5\":\"\",\"6\":\"0.47078\\\\u21e4\",\"7\":\"0.17706\"},{\"0\":\"\\\\u0000\",\"1\":\"\\\\u0000\",\"2\":\"\",\"3\":\"\\\\u0000\",\"4\":\"\\\\u0000\",\"5\":\"\",\"6\":\"\\\\u0000\",\"7\":\"\\\\u0000\"},{\"0\":\"0.26859\",\"1\":\"0.15327\",\"2\":\"\",\"3\":\"0.26365\",\"4\":\"0.15017\",\"5\":\"\",\"6\":\"0.24684\",\"7\":\"0.13256\"},{\"0\":\"(\\\\n)\",\"1\":\"(\",\"2\":\")\",\"3\":\"(\\\\n)\",\"4\":\"(\",\"5\":\")\",\"6\":\"(\\\\n)\",\"7\":\"(\\\\n)\"},{\"0\":\"N\\\\n680.00000\",\"1\":\"681.00000\",\"2\":\"\",\"3\":\"680.00000\",\"4\":\"681.00000\",\"5\":\"\",\"6\":\"680.00000\",\"7\":\"681.00000\"},{\"0\":\"\\'2\\\\n0.68741\",\"1\":\"0.68212\",\"2\":\"\",\"3\":\"0.60737\",\"4\":\"0.60198\",\"5\":\"\",\"6\":\"0.71213\",\"7\":\"0.71126\"}]'}\n",
      "Source: camelot, Table: {'table_number': 28, 'page_number': 21, 'data': '[{\"0\":\"\",\"1\":\"Table 9: Regression of LLM-exposure scores on prior measures of occupational exposure to AI and automation.\"},{\"0\":\"We also include annualized wages from the BLS-OES survey in May 2021. Each measure is kept\",\"1\":\"in its\"},{\"0\":\"original scale, with the exception of routine cognitive and routine manual scores from (Acemoglu and Autor,\",\"1\":\"\"},{\"0\":\"2011a). Those two scores are standardized to mean zero and variance 1. Generally we \\\\ufb01nd strong positive\",\"1\":\"\"},{\"0\":\"\",\"1\":\"associations with previous e\\\\ufb00orts, though large residual variance to still be explained by our new measures.\"},{\"0\":\"Columns 1 and 2 are based on our main V exposure measure from GPT-4 ratings. Columns 3 and 4 are\",\"1\":\"\"},{\"0\":\"based on a similar slightly di\\\\ufb00erent exposure rubric also rated by GPT-4 for robustness. Columns 5 and 6\",\"1\":\"\"},{\"0\":\"re\\\\ufb02ect human ratings on the same rubric as columns 1 and 2. Occupation-level scores are built using the\",\"1\":\"\"},{\"0\":\"core\\\\/supplemental task weights, assigning supplemental tasks as having half the weight of core tasks.\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 29, 'page_number': 22, 'data': '[{\"0\":\"6\\\\nDiscussion\"},{\"0\":\"6.1\\\\nGPTs as a General-Purpose Technology\"},{\"0\":\"Earlier in this paper we discuss the possibility that LLMs could be classi\\\\ufb01ed as a general-purpose technology.\"},{\"0\":\"This classi\\\\ufb01cation requires LLMs to meet three core criteria:\\\\nimprovement over time, pervasiveness throughout\"},{\"0\":\"the economy, and the ability to spawn complementary innovations (Lipsey et al., 2005). Evidence from the AI\"},{\"0\":\"and machine learning literature thoroughly demonstrates that LLMs meet the \\\\ufb01rst criteria \\\\u2013 they are improving\"},{\"0\":\"in capabilities over time with the ability to complete or be helpful for an increasingly complex set of tasks and\"},{\"0\":\"use-cases (see 2.1). This paper presents evidence to support the latter two criteria, \\\\ufb01nding that LLMs on their\"},{\"0\":\"own can have pervasive impacts across the economy, and that complementary innovations enabled by LLMs \\\\u2013\"},{\"0\":\"particularly via software and digital tools \\\\u2013 can have widespread application to economic activity.\"},{\"0\":\"Figure 3 o\\\\ufb00ers one illustration of the potential economic impact of complementary software built on top of\"},{\"0\":\"LLMs. Taking the di\\\\ufb00erence in the y-axis (the share of all occupations) between U and Z at a given point along\"},{\"0\":\"the x-axis (the share of tasks within an occupation that are exposed) gives the aggregate within-occupation\"},{\"0\":\"exposure potential attributable to tools and software over and above direct exposure from LLMs on their\"},{\"0\":\"own. The di\\\\ufb00erence in means across all tasks between U and Z of 0.42 using the GPT-4 annotations and 0.32\"},{\"0\":\"using the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\"},{\"0\":\"task-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Z of 0.14\"},{\"0\":\"based on both human annotations and GPT-4 annotations). While our \\\\ufb01ndings suggest that out-of-the-box\"},{\"0\":\"these models are relevant\\\\nto a meaningful share of workers and tasks,\\\\nthey also suggest that the software\"},{\"0\":\"innovations they spawn could drive a much broader impact.\"},{\"0\":\"One component of the pervasiveness of a technology is its level of adoption by businesses and users.\"},{\"0\":\"This paper does not systematically analyze adoption of these models, however,\\\\nthere is early qualitative\"},{\"0\":\"evidence that adoption and use of LLMs is becoming increasingly widespread. The power of relatively\"},{\"0\":\"simple UI improvements on top of LLMs was evident in the rollout of ChatGPT \\\\u2013 wherein versions of the\"},{\"0\":\"underlying language model had been previously available via API, but usage skyrocketed after the release of\"},{\"0\":\"the ChatGPT interface.\\\\n(Chow, 2023; OpenAI, 2022) Following this release, a number of commercial surveys\"},{\"0\":\"indicate that \\\\ufb01rm and worker adoption of LLMs has increased over the past several months.\\\\n(Constantz, 2023;\"},{\"0\":\"ResumeBuilder.com, 2023)\"},{\"0\":\"Widespread adoption of these models requires addressing existing bottlenecks. A key determinant of\"},{\"0\":\"their utility is the level of con\\\\ufb01dence humans place in them and how humans adapt their habits. For instance,\"},{\"0\":\"in the legal profession,\\\\nthe models\\\\u2019 usefulness depends on whether\\\\nlegal professionals can trust model\"},{\"0\":\"outputs without verifying original documents or conducting independent research. The cost and \\\\ufb02exibility\"},{\"0\":\"of the technology, worker and \\\\ufb01rm preferences, and incentives also signi\\\\ufb01cantly in\\\\ufb02uence the adoption of\"},{\"0\":\"tools built on top of LLMs.\\\\nIn this way, adoption may be driven by progress on some of the ethical and\"},{\"0\":\"safety risks associated with LLMs: bias, fabrication of facts, and misalignment,\\\\nto name a few OpenAI\"},{\"0\":\"(2023a). Moreover, the adoption of LLMs will vary across di\\\\ufb00erent economic sectors due to factors such\"},{\"0\":\"as data availability, regulatory environment, and the distribution of power and interests. Consequently, a\"},{\"0\":\"comprehensive understanding of the adoption and use of LLMs by workers and \\\\ufb01rms requires a more in-depth\"},{\"0\":\"exploration of these intricacies.\"},{\"0\":\"One possibility is that time savings and seamless application will hold greater importance than quality\"},{\"0\":\"improvement for the majority of tasks. Another is that the initial focus will be on augmentation, followed by\"},{\"0\":\"automation (Huang and Rust, 2018). One way this might take shape is through an augmentation phase where\"},{\"0\":\"jobs \\\\ufb01rst become more precarious (e.g., writers becoming freelancers) before transitioning to full automation.\"}]'}\n",
      "Source: camelot, Table: {'table_number': 30, 'page_number': 23, 'data': '[{\"0\":\"\",\"1\":\"WORKING PAPER\"},{\"0\":\"6.2\\\\nImplications for US Public Policy\",\"1\":\"\"},{\"0\":\"The introduction of automation technologies,\",\"1\":\"including LLMs, has previously been linked to heightened\"},{\"0\":\"economic disparity and labor disruption, which may give rise to adverse downstream e\\\\ufb00ects (Acemoglu and\",\"1\":\"\"},{\"0\":\"\",\"1\":\"Restrepo, 2022a; Acemoglu, 2002; Moll et al., 2021; Klinova and Korinek, 2021; Weidinger et al., 2021,\"},{\"0\":\"2022). Our results examining worker exposure in the United States underscore the need for societal and policy\",\"1\":\"\"},{\"0\":\"preparedness to the potential economic disruption posed by LLMs and the complementary technologies\",\"1\":\"\"},{\"0\":\"that they spawn. While it is outside the scope of this paper to recommend speci\\\\ufb01c policy prescriptions to\",\"1\":\"\"},{\"0\":\"smooth the transition to an economy with increasingly widespread LLM adoption, prior work such as (Autor\",\"1\":\"\"},{\"0\":\"\",\"1\":\"et al., 2022b) has articulated several important directions for US policy related to education, worker training,\"},{\"0\":\"reforms to safety net programs, and more.\",\"1\":\"\"},{\"0\":\"6.3\\\\nLimitations and Future Work\",\"1\":\"\"},{\"0\":\"In addition to those discussed above, we highlight some particular limitations of this work that warrant further\",\"1\":\"\"},{\"0\":\"investigation. Primarily, our focus on the United States restricts the generalizability of our \\\\ufb01ndings to other\",\"1\":\"\"},{\"0\":\"nations where the adoption and impact of generative models may di\\\\ufb00er due to factors such as industrial\",\"1\":\"\"},{\"0\":\"\",\"1\":\"organization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\"},{\"0\":\"We hope to address this limitation by extending the study\\\\u2019s scope and by sharing our methods so other\",\"1\":\"\"},{\"0\":\"researchers can build on them.\",\"1\":\"\"},{\"0\":\"\",\"1\":\"Subsequent research e\\\\ufb00orts should consider two additional studies: one exploring LLM adoption patterns\"},{\"0\":\"across various sectors and occupations, and another scrutinizing the actual capabilities and limitations of\",\"1\":\"\"},{\"0\":\"\",\"1\":\"state-of-the-art models in relation to worker activities beyond the scope of our exposure scores. For example,\"},{\"0\":\"despite recent advances in multimodal capabilities with GPT-4, we did not consider vision capabilities in\",\"1\":\"\"},{\"0\":\"the U ratings on direct LLMs-exposure (OpenAI, 2023b). Future work should consider the impact of such\",\"1\":\"\"},{\"0\":\"capability advances as they unfold. Furthermore, we acknowledge that there may be discrepancies between\",\"1\":\"\"},{\"0\":\"theoretical and practical performance, particularly in complex, open-ended, and domain-speci\\\\ufb01c tasks.\",\"1\":\"\"}]'}\n",
      "Source: camelot, Table: {'table_number': 31, 'page_number': 24, 'data': '[{\"0\":\"\",\"1\":\"WORKING PAPER\"},{\"0\":\"\",\"1\":\"of LLMs on the workforce, policymakers and stakeholders can make more informed decisions to navigate the\"},{\"0\":\"complex landscape of AI and its role in shaping the future of work.\",\"1\":\"\"},{\"0\":\"7.1\",\"1\":\"LLM Conclusion (GPT-4\\\\u2019s Version)\"},{\"0\":\"\",\"1\":\"Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential technolog-\"},{\"0\":\"\",\"1\":\"ical growth, permeating tasks, greatly impacting professions. This study probes GPTs\\\\u2019 potential trajectories,\"},{\"0\":\"presenting a groundbreaking rubric to gauge tasks\\\\u2019 GPT exposure, particularly in the U.S. labor market.\",\"1\":\"\"},{\"0\":\"7.2\",\"1\":\"LLM Conclusion (Author-Augmented Version)\"},{\"0\":\"\",\"1\":\"Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential techno-\"},{\"0\":\"\",\"1\":\"logical growth, permeating tasks, gutting professional management. Gauging possible trajectories? Generate\"},{\"0\":\"pioneering taxonomies, gather policymakers together, generalize past today.\",\"1\":\"\"},{\"0\":\"Acknowledgments\",\"1\":\"\"},{\"0\":\"Thank you to the group of annotators who helped us annotate task exposure, including Muhammad Ahmed\",\"1\":\"\"},{\"0\":\"\",\"1\":\"Saeed, Bongane Zitha, Merve \\\\u00d6zen \\\\u015eenen, J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\"},{\"0\":\"\",\"1\":\"Michael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signi\\\\ufb01cant\"},{\"0\":\"feedback on this paper.\",\"1\":\"\"},{\"0\":\"\",\"1\":\"We thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\"},{\"0\":\"\",\"1\":\"GPT-4. We thank Lama Ahmad, Donald Bakong, Seth Benzell, Erik Brynjolfsson, Parfait Eloundou-Enyegue,\"},{\"0\":\"\",\"1\":\"Carl Frey, Sarah Giroux, Gillian Had\\\\ufb01eld, Johannes Heidecke, Alan Hickey, Eric Horvitz, Shengli Hu,\"},{\"0\":\"Ashyana Kachra, Christina Kim, Katya Klinova, Daniel Kokotajlo, Gretchen Krueger, Michael Lampe, Aalok\",\"1\":\"\"},{\"0\":\"\",\"1\":\"Mehta, Larissa Schiavo, Daniel Selsam, Sarah Shoker, Prasanna Tambe, and Je\\\\ufb00 Wu for feedback and edits at\"},{\"0\":\"various stages of the project.\",\"1\":\"\"},{\"0\":\"LLM assistance statement\",\"1\":\"\"},{\"0\":\"GPT-4 and ChatGPT were used for writing, coding, and formatting assistance in this project.\",\"1\":\"\"}]'}\n",
      "Source: tabula, Table: {'table_number': 0, 'page_number': '', 'data': '[{\"Unnamed: 0\":null,\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":\"implications.\"},{\"Unnamed: 0\":\"1\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":\"Introduction\"},{\"Unnamed: 0\":\"As shown in Figure 1, recent years, months, and weeks have seen remarkable progress in the field of generative\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"AI and large language models (LLMs). While the public often associates LLMs with various iterations of the\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"Generative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"limited to transformer-based models (Devlin et al., 2019). LLMs can process and produce various forms of\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"sequential data, including assembly language, protein sequences and chess games, extending beyond natural\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"language applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"our rubric that these should be considered similar to the GPT-family of models available via ChatGPT or\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"the OpenAI Playground (which at the time of labeling included models in the GPT-3.5 family but not in the\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null},{\"Unnamed: 0\":\"GPT-4 family). We examine LLMs with text- and code-generating abilities, use the term \\\\\"generative AI\\\\\" to\",\"general-purpose technologies, indicating that they could have considerable economic, social, and policy\":null}]'}\n",
      "Source: tabula, Table: {'table_number': 1, 'page_number': '', 'data': '[{\"Comparison\":\"GPT-4, Rubric 1; Human\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"80.8%\",\"Pearson\\\\u2019s\":0.223},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"65.6%\",\"Pearson\\\\u2019s\":0.591},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"82.1%\",\"Pearson\\\\u2019s\":0.654},{\"Comparison\":\"GPT-4, Rubric 2; Human\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"81.8%\",\"Pearson\\\\u2019s\":0.221},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"65.6%\",\"Pearson\\\\u2019s\":0.538},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"79.5%\",\"Pearson\\\\u2019s\":0.589},{\"Comparison\":\"GPT-4, Rubric 1; GPT-4, Rubric 2\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"91.1%\",\"Pearson\\\\u2019s\":0.611},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"76.0%\",\"Pearson\\\\u2019s\":0.705},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"82.4%\",\"Pearson\\\\u2019s\":0.68}]'}\n",
      "Source: tabula, Table: {'table_number': 2, 'page_number': '', 'data': '[{\"Basic Skill\":null,\"U V\":\"(std err) (std err)\",\"Unnamed: 0\":null,\"Z\":\"(std err)\"},{\"Basic Skill\":null,\"U V\":\"All skill importance scores are normalized to be between 0 and 1.\",\"Unnamed: 0\":null,\"Z\":null},{\"Basic Skill\":\"Constant\",\"U V\":\"0.082*** -0.112***\",\"Unnamed: 0\":null,\"Z\":\"0.300***\"},{\"Basic Skill\":null,\"U V\":\"(0.011) (0.011)\",\"Unnamed: 0\":null,\"Z\":\"(0.057)\"},{\"Basic Skill\":\"Active Listening\",\"U V\":\"0.128** 0.214***\",\"Unnamed: 0\":null,\"Z\":\"0.449***\"},{\"Basic Skill\":null,\"U V\":\"(0.047) (0.043)\",\"Unnamed: 0\":null,\"Z\":\"(0.027)\"},{\"Basic Skill\":\"Mathematics\",\"U V\":\"-0.127*** 0.161***\",\"Unnamed: 0\":null,\"Z\":\"0.787***\"},{\"Basic Skill\":null,\"U V\":\"(0.026) (0.021)\",\"Unnamed: 0\":null,\"Z\":\"(0.049)\"},{\"Basic Skill\":\"Reading Comprehension\",\"U V\":\"0.153*** 0.470***\",\"Unnamed: 0\":null,\"Z\":\"-0.346***\"},{\"Basic Skill\":null,\"U V\":\"(0.041) (0.037)\",\"Unnamed: 0\":null,\"Z\":\"(0.017)\"},{\"Basic Skill\":\"Science\",\"U V\":\"-0.114*** -0.230***\",\"Unnamed: 0\":null,\"Z\":\"-0.346***\"},{\"Basic Skill\":null,\"U V\":\"(0.014) (0.012)\",\"Unnamed: 0\":null,\"Z\":\"(0.017)\"},{\"Basic Skill\":\"Speaking\",\"U V\":\"-0.028 0.133***\",\"Unnamed: 0\":null,\"Z\":\"0.294***\"},{\"Basic Skill\":null,\"U V\":\"(0.039) (0.033)\",\"Unnamed: 0\":null,\"Z\":\"(0.042)\"},{\"Basic Skill\":\"Writing\",\"U V\":\"0.368*** 0.467***\",\"Unnamed: 0\":null,\"Z\":\"0.566***\"},{\"Basic Skill\":null,\"U V\":\"(0.042) (0.037)\",\"Unnamed: 0\":null,\"Z\":\"(0.047)\"},{\"Basic Skill\":\"Active Learning\",\"U V\":\"-0.157*** -0.065**\",\"Unnamed: 0\":null,\"Z\":\"0.028\"},{\"Basic Skill\":null,\"U V\":\"(0.027) (0.024)\",\"Unnamed: 0\":null,\"Z\":\"(0.032)\"},{\"Basic Skill\":\"Critical Thinking\",\"U V\":\"-0.264*** -0.196***\",\"Unnamed: 0\":null,\"Z\":\"-0.129**\"},{\"Basic Skill\":null,\"U V\":\"(0.036) (0.033)\",\"Unnamed: 0\":null,\"Z\":\"(0.042)\"},{\"Basic Skill\":\"Learning Strategies\",\"U V\":\"-0.072* -0.209***\",\"Unnamed: 0\":null,\"Z\":\"-0.346***\"},{\"Basic Skill\":null,\"U V\":\"(0.028) (0.025)\",\"Unnamed: 0\":null,\"Z\":\"(0.034)\"},{\"Basic Skill\":\"Monitoring\",\"U V\":\"-0.067** -0.149***\",\"Unnamed: 0\":null,\"Z\":\"-0.232***\"},{\"Basic Skill\":null,\"U V\":\"(0.023) 0.020)\",\"Unnamed: 0\":null,\"Z\":\"(0.026)\"}]'}\n",
      "Source: tabula, Table: {'table_number': 3, 'page_number': '', 'data': '[{\"Job\":\"Zone\",\"Preparation\":\"Required\",\"Education\":\"Required\",\"Example Occupations\":null,\"Median\":\"Income\",\"Tot Emp\":\"(000s)\",\"H\":\"U\",\"M\":\"U\",\"H.1\":\"V\",\"M.1\":\"V\",\"H.2\":\"Z\",\"M.2\":\"Z\"},{\"Job\":\"1\",\"Preparation\":\"None or little\",\"Education\":\"High school\",\"Example Occupations\":\"Food preparation workers,\",\"Median\":\"$30,230\",\"Tot Emp\":\"13,100\",\"H\":\"0.03\",\"M\":\"0.04\",\"H.1\":\"0.06\",\"M.1\":\"0.06\",\"H.2\":\"0.09\",\"M.2\":\"0.08\"},{\"Job\":null,\"Preparation\":\"(0-3 months)\",\"Education\":\"diploma or GED\",\"Example Occupations\":\"dishwashers, floor sanders\",\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":null,\"Preparation\":null,\"Education\":\"(otional)\",\"Example Occupations\":null,\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":\"2\",\"Preparation\":\"Some (3-12\",\"Education\":\"High school\",\"Example Occupations\":\"Orderlies, customer\",\"Median\":\"$38,215\",\"Tot Emp\":\"73,962\",\"H\":\"0.07\",\"M\":\"0.12\",\"H.1\":\"0.16\",\"M.1\":\"0.20\",\"H.2\":\"0.24\",\"M.2\":\"0.27\"},{\"Job\":null,\"Preparation\":\"months)\",\"Education\":\"diploma\",\"Example Occupations\":\"service representatives,\",\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":null,\"Preparation\":null,\"Education\":null,\"Example Occupations\":\"tellers\",\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":\"3\",\"Preparation\":\"Medium (1-2\",\"Education\":\"Vocational school,\",\"Example Occupations\":\"Electricians, barbers,\",\"Median\":\"$54,815\",\"Tot Emp\":\"37,881\",\"H\":\"0.11\",\"M\":\"0.14\",\"H.1\":\"0.26\",\"M.1\":\"0.32\",\"H.2\":\"0.41\",\"M.2\":\"0.51\"},{\"Job\":null,\"Preparation\":\"years)\",\"Education\":\"on-the-job training,\",\"Example Occupations\":\"medical assistants\",\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":null,\"Preparation\":null,\"Education\":\"or associate\\\\u2019s\",\"Example Occupations\":null,\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":null,\"Preparation\":null,\"Education\":\"degree\",\"Example Occupations\":null,\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":\"4\",\"Preparation\":\"Considerable\",\"Education\":\"Bachelor\\\\u2019s degree\",\"Example Occupations\":\"Database administrators,\",\"Median\":\"$77,345\",\"Tot Emp\":\"56,833\",\"H\":\"0.23\",\"M\":\"0.18\",\"H.1\":\"0.47\",\"M.1\":\"0.51\",\"H.2\":\"0.71\",\"M.2\":\"0.85\"},{\"Job\":null,\"Preparation\":\"(2-4 years)\",\"Education\":null,\"Example Occupations\":\"graphic designers, cost\",\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":null,\"Preparation\":null,\"Education\":null,\"Example Occupations\":\"estimators\",\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null},{\"Job\":\"5\",\"Preparation\":\"Extensive (4+\",\"Education\":\"Master\\\\u2019s degree or\",\"Example Occupations\":\"Pharmacists, lawyers,\",\"Median\":\"$81,980\",\"Tot Emp\":\"21,221\",\"H\":\"0.23\",\"M\":\"0.13\",\"H.1\":\"0.43\",\"M.1\":\"0.45\",\"H.2\":\"0.63\",\"M.2\":\"0.76\"},{\"Job\":null,\"Preparation\":\"years)\",\"Education\":\"higher\",\"Example Occupations\":\"astronomers\",\"Median\":null,\"Tot Emp\":null,\"H\":null,\"M\":null,\"H.1\":null,\"M.1\":null,\"H.2\":null,\"M.2\":null}]'}\n",
      "Source: tabula, Table: {'table_number': 4, 'page_number': '', 'data': '[{\"On The Job Training Required\":\"None\",\"Median Income\":\"$77,440\",\"Tot Emp (000s)\":\"90,776\",\"H U\":0.2,\"M U\":0.16,\"H V\":0.42,\"M V\":0.46,\"H Z\":0.63,\"M Z\":0.76},{\"On The Job Training Required\":\"Apprenticeship\",\"Median Income\":\"$55,995\",\"Tot Emp (000s)\":\"3,066\",\"H U\":0.01,\"M U\":0.02,\"H V\":0.04,\"M V\":0.06,\"H Z\":0.07,\"M Z\":0.1},{\"On The Job Training Required\":\"Internship\\\\/residency\",\"Median Income\":\"$77,110\",\"Tot Emp (000s)\":\"3,063\",\"H U\":0.16,\"M U\":0.06,\"H V\":0.36,\"M V\":0.38,\"H Z\":0.55,\"M Z\":0.71},{\"On The Job Training Required\":\"Short-term on-the-job training\",\"Median Income\":\"$33,370\",\"Tot Emp (000s)\":\"66,234\",\"H U\":0.11,\"M U\":0.15,\"H V\":0.21,\"M V\":0.25,\"H Z\":0.32,\"M Z\":0.34},{\"On The Job Training Required\":\"Moderate-term on-the-job training\",\"Median Income\":\"$46,880\",\"Tot Emp (000s)\":\"31,285\",\"H U\":0.09,\"M U\":0.12,\"H V\":0.21,\"M V\":0.25,\"H Z\":0.32,\"M Z\":0.38},{\"On The Job Training Required\":\"Long-term on-the-job training\",\"Median Income\":\"$48,925\",\"Tot Emp (000s)\":\"5,070\",\"H U\":0.08,\"M U\":0.1,\"H V\":0.18,\"M V\":0.22,\"H Z\":0.28,\"M Z\":0.33}]'}\n",
      "Source: tabula, Table: {'table_number': 5, 'page_number': '', 'data': '[{\"Unnamed: 0\":\"GPT-4 Exposure Rating 1\",\"Min\":0.0,\"25th Perc.\":0.13,\"Median\":0.34,\"75th Perc\":0.5,\"Max\":1.0,\"Mean\":0.33,\"Std. Dev.\":0.22,\"Count\":750},{\"Unnamed: 0\":\"GPT-4 Exposure Rating 2\",\"Min\":0.0,\"25th Perc.\":0.09,\"Median\":0.24,\"75th Perc\":0.4,\"Max\":0.98,\"Mean\":0.26,\"Std. Dev.\":0.2,\"Count\":750},{\"Unnamed: 0\":\"Human Exposure Rating\",\"Min\":0.0,\"25th Perc.\":0.09,\"Median\":0.29,\"75th Perc\":0.47,\"Max\":0.84,\"Mean\":0.29,\"Std. Dev.\":0.21,\"Count\":750},{\"Unnamed: 0\":\"Software (Webb)\",\"Min\":1.0,\"25th Perc.\":25.0,\"Median\":50.0,\"75th Perc\":75.0,\"Max\":100.0,\"Mean\":50.69,\"Std. Dev.\":30.05,\"Count\":750},{\"Unnamed: 0\":\"Robot (Webb)\",\"Min\":1.0,\"25th Perc.\":22.0,\"Median\":52.0,\"75th Perc\":69.0,\"Max\":100.0,\"Mean\":48.61,\"Std. Dev.\":28.61,\"Count\":750},{\"Unnamed: 0\":\"AI (Webb)\",\"Min\":1.0,\"25th Perc.\":28.0,\"Median\":55.0,\"75th Perc\":82.0,\"Max\":100.0,\"Mean\":54.53,\"Std. Dev.\":29.65,\"Count\":750},{\"Unnamed: 0\":\"Suitability for Machine Learning\",\"Min\":2.6,\"25th Perc.\":2.84,\"Median\":2.95,\"75th Perc\":3.12,\"Max\":3.55,\"Mean\":2.99,\"Std. Dev.\":0.18,\"Count\":750},{\"Unnamed: 0\":\"Normalized Routine Cognitive\",\"Min\":-3.05,\"25th Perc.\":-0.46,\"Median\":0.1,\"75th Perc\":0.63,\"Max\":3.42,\"Mean\":0.07,\"Std. Dev.\":0.86,\"Count\":750},{\"Unnamed: 0\":\"Normalized Routine Manual\",\"Min\":-1.81,\"25th Perc.\":-0.81,\"Median\":-0.11,\"75th Perc\":0.73,\"Max\":2.96,\"Mean\":0.05,\"Std. Dev.\":1.01,\"Count\":750},{\"Unnamed: 0\":\"AI Occupational Exposure Score\",\"Min\":1.42,\"25th Perc.\":3.09,\"Median\":3.56,\"75th Perc\":4.04,\"Max\":6.54,\"Mean\":3.56,\"Std. Dev.\":0.7,\"Count\":750},{\"Unnamed: 0\":\"Frey & Osborne Automation\",\"Min\":0.0,\"25th Perc.\":0.07,\"Median\":0.59,\"75th Perc\":0.88,\"Max\":0.99,\"Mean\":0.5,\"Std. Dev.\":0.38,\"Count\":681},{\"Unnamed: 0\":\"Log Avg. Salary\",\"Min\":10.13,\"25th Perc.\":10.67,\"Median\":11.0,\"75th Perc\":11.34,\"Max\":12.65,\"Mean\":11.02,\"Std. Dev.\":0.45,\"Count\":749}]'}\n",
      "Source: tabula, Table: {'table_number': 6, 'page_number': '', 'data': '[{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(1) (2)\",\"GPT-4 Exposure Rating 2\":\"(3) (4)\",\"Human Exposure Rating\":\"(5) (6)\"},{\"Unnamed: 0\":\"Software (Webb)\",\"GPT-4 Exposure Rating 1\":\"0.00113\\\\u21e4\\\\u21e4\\\\u21e4 0.00123\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.00111\\\\u21e4\\\\u21e4\\\\u21e4 0.00119\\\\u21e4\\\\u21e4\\\\u21e4\",\"Human Exposure Rating\":\"0.00096\\\\u21e4\\\\u21e4\\\\u21e4 0.00101\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.00031) (0.00031)\",\"GPT-4 Exposure Rating 2\":\"(0.00031) (0.00031)\",\"Human Exposure Rating\":\"(0.00031) (0.00031)\"},{\"Unnamed: 0\":\"Robot (Webb)\",\"GPT-4 Exposure Rating 1\":\"0.00378\\\\u21e4\\\\u21e4\\\\u21e4 0.00405\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.00377\\\\u21e4\\\\u21e4\\\\u21e4 0.00399\\\\u21e4\\\\u21e4\\\\u21e4\",\"Human Exposure Rating\":\"0.00371\\\\u21e4\\\\u21e4\\\\u21e4 0.00383\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.00032) (0.00031)\",\"GPT-4 Exposure Rating 2\":\"(0.00034) (0.00033)\",\"Human Exposure Rating\":\"(0.00029) (0.00028)\"},{\"Unnamed: 0\":\"AI (Webb)\",\"GPT-4 Exposure Rating 1\":\"0.00080\\\\u21e4\\\\u21e4\\\\u21e4 0.00090\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.00036 0.00045\",\"Human Exposure Rating\":\"0.00067\\\\u21e4\\\\u21e4 0.00071\\\\u21e4\\\\u21e4\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.00030) (0.00029)\",\"GPT-4 Exposure Rating 2\":\"(0.00030) (0.00030)\",\"Human Exposure Rating\":\"(0.00030) (0.00030)\"},{\"Unnamed: 0\":\"Suitability for Machine Learning\",\"GPT-4 Exposure Rating 1\":\"0.29522\\\\u21e4\\\\u21e4\\\\u21e4 0.26888\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.28468\\\\u21e4\\\\u21e4\\\\u21e4 0.26245\\\\u21e4\\\\u21e4\\\\u21e4\",\"Human Exposure Rating\":\"0.19514\\\\u21e4\\\\u21e4\\\\u21e4 0.18373\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.04503) (0.04418)\",\"GPT-4 Exposure Rating 2\":\"(0.04404) (0.04342)\",\"Human Exposure Rating\":\"(0.03990) (0.03886)\"},{\"Unnamed: 0\":\"Normalized Routine Cognitive\",\"GPT-4 Exposure Rating 1\":\"0.06601\\\\u21e4\\\\u21e4\\\\u21e4 0.06868\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.04743\\\\u21e4\\\\u21e4\\\\u21e4 0.05015\\\\u21e4\\\\u21e4\\\\u21e4\",\"Human Exposure Rating\":\"0.03568\\\\u21e4\\\\u21e4\\\\u21e4 0.03659\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.00886) (0.00894)\",\"GPT-4 Exposure Rating 2\":\"(0.00872) (0.00879)\",\"Human Exposure Rating\":\"(0.00671) (0.00669)\"},{\"Unnamed: 0\":\"Normalized Routine Manual\",\"GPT-4 Exposure Rating 1\":\"0.11147\\\\u21e4\\\\u21e4\\\\u21e4 0.11371\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.09390\\\\u21e4\\\\u21e4\\\\u21e4 0.09561\\\\u21e4\\\\u21e4\\\\u21e4\",\"Human Exposure Rating\":\"0.11045\\\\u21e4\\\\u21e4\\\\u21e4 0.11152\\\\u21e4\\\\u21e4\\\\u21e4\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.00785) (0.00789)\",\"GPT-4 Exposure Rating 2\":\"(0.00817) (0.00818)\",\"Human Exposure Rating\":\"(0.00741) (0.00744)\"},{\"Unnamed: 0\":\"AI Occupational Exposure Score\",\"GPT-4 Exposure Rating 1\":\"0.00993 0.02465\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.01537 0.00265\",\"Human Exposure Rating\":\"0.00630 0.01252\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.01107) (0.01059)\",\"GPT-4 Exposure Rating 2\":\"(0.01160) (0.01114)\",\"Human Exposure Rating\":\"(0.00918) (0.00845)\"},{\"Unnamed: 0\":\"Frey & Osborne Automation\",\"GPT-4 Exposure Rating 1\":\"0.03024\\\\u21e4 0.03950\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.00364 0.01217\",\"Human Exposure Rating\":\"0.03890\\\\u21e4\\\\u21e4 0.04253\\\\u21e4\\\\u21e4\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.01835) (0.01841)\",\"GPT-4 Exposure Rating 2\":\"(0.02007) (0.01972)\",\"Human Exposure Rating\":\"(0.01883) (0.01858)\"},{\"Unnamed: 0\":\"Log Avg. Salary\",\"GPT-4 Exposure Rating 1\":\"0.05804\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.04863\\\\u21e4\\\\u21e4\\\\u21e4\",\"Human Exposure Rating\":\"0.02531\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.01870)\",\"GPT-4 Exposure Rating 2\":\"(0.01860)\",\"Human Exposure Rating\":\"(0.01727)\"},{\"Unnamed: 0\":\"Constant\",\"GPT-4 Exposure Rating 1\":\"1.12937\\\\u21e4\\\\u21e4\\\\u21e4 0.45743\\\\u21e4\\\\u21e4\\\\u21e4\",\"GPT-4 Exposure Rating 2\":\"0.96117\\\\u21e4\\\\u21e4\\\\u21e4 0.39935\\\\u21e4\\\\u21e4\\\\u21e4\",\"Human Exposure Rating\":\"0.47078\\\\u21e4 0.17706\"},{\"Unnamed: 0\":null,\"GPT-4 Exposure Rating 1\":\"(0.26859) (0.15327)\",\"GPT-4 Exposure Rating 2\":\"(0.26365) (0.15017)\",\"Human Exposure Rating\":\"(0.24684) (0.13256)\"}]'}\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    file_path = folder_path + \"/\" + filename\n",
    "    file_name = os.path.basename(file_path)\n",
    "    df_file = pd.DataFrame()\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} process {file_name}\")\n",
    "\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} extract table\")\n",
    "\n",
    "    all_tables = []\n",
    "    for package in [\"camelot\", \"tabula\"]:\n",
    "        print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} extract table with {package}\")\n",
    "        try:\n",
    "            tables_from_package = extract_tables(file_path, pages=\"all\", package=package) # list of json\n",
    "            for table in tables_from_package:\n",
    "                all_tables.append({\"table\": table, \"source\": package})\n",
    "        except Exception as e:\n",
    "            print(\"----Error: cannot extract table\")\n",
    "            print(f\"----error: {e}\")\n",
    "\n",
    "# Now you can access each table along with its source\n",
    "for entry in all_tables:\n",
    "    print(f\"Source: {entry['source']}, Table: {entry['table']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "619a6f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table_number': 1,\n",
       " 'page_number': '',\n",
       " 'data': '[{\"Comparison\":\"GPT-4, Rubric 1; Human\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"80.8%\",\"Pearson\\\\u2019s\":0.223},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"65.6%\",\"Pearson\\\\u2019s\":0.591},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"82.1%\",\"Pearson\\\\u2019s\":0.654},{\"Comparison\":\"GPT-4, Rubric 2; Human\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"81.8%\",\"Pearson\\\\u2019s\":0.221},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"65.6%\",\"Pearson\\\\u2019s\":0.538},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"79.5%\",\"Pearson\\\\u2019s\":0.589},{\"Comparison\":\"GPT-4, Rubric 1; GPT-4, Rubric 2\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"91.1%\",\"Pearson\\\\u2019s\":0.611},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"76.0%\",\"Pearson\\\\u2019s\":0.705},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"82.4%\",\"Pearson\\\\u2019s\":0.68}]'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda element: element['source']=='tabula',all_tables))[1]['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "489c8c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"Comparison\":\"GPT-4, Rubric 1; Human\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"80.8%\",\"Pearson\\\\u2019s\":0.223},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"65.6%\",\"Pearson\\\\u2019s\":0.591},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"82.1%\",\"Pearson\\\\u2019s\":0.654},{\"Comparison\":\"GPT-4, Rubric 2; Human\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"81.8%\",\"Pearson\\\\u2019s\":0.221},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"65.6%\",\"Pearson\\\\u2019s\":0.538},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"79.5%\",\"Pearson\\\\u2019s\":0.589},{\"Comparison\":\"GPT-4, Rubric 1; GPT-4, Rubric 2\",\"W\":\"U\",\"Weighting\":\"E1\",\"Agreement\":\"91.1%\",\"Pearson\\\\u2019s\":0.611},{\"Comparison\":null,\"W\":\"V\",\"Weighting\":\"E1 + .5*E2\",\"Agreement\":\"76.0%\",\"Pearson\\\\u2019s\":0.705},{\"Comparison\":null,\"W\":\"Z\",\"Weighting\":\"E1 + E2\",\"Agreement\":\"82.4%\",\"Pearson\\\\u2019s\":0.68}]'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda element: element['source']=='tabula',all_tables))[1]['table']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c03b41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table_number': 10,\n",
       " 'page_number': 8,\n",
       " 'data': '[{\"0\":\"corresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},{\"0\":\"nearly the entire task.\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},{\"0\":\"Comparison\",\"1\":\"W\",\"2\":\"Weighting\",\"3\":\"Agreement\",\"4\":\"Pearson\\\\u2019s\"},{\"0\":\"GPT-4, Rubric 1; Human\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"80.8%\",\"4\":\"0.223\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"65.6%\",\"4\":\"0.591\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"82.1%\",\"4\":\"0.654\"},{\"0\":\"GPT-4, Rubric 2; Human\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"81.8%\",\"4\":\"0.221\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"65.6%\",\"4\":\"0.538\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"79.5%\",\"4\":\"0.589\"},{\"0\":\"GPT-4, Rubric 1; GPT-4, Rubric 2\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"91.1%\",\"4\":\"0.611\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"76.0%\",\"4\":\"0.705\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"82.4%\",\"4\":\"0.680\"}]'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda element: element['source']=='camelot',all_tables))[10]['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2df085d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"0\":\"corresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},{\"0\":\"nearly the entire task.\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},{\"0\":\"Comparison\",\"1\":\"W\",\"2\":\"Weighting\",\"3\":\"Agreement\",\"4\":\"Pearson\\\\u2019s\"},{\"0\":\"GPT-4, Rubric 1; Human\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"80.8%\",\"4\":\"0.223\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"65.6%\",\"4\":\"0.591\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"82.1%\",\"4\":\"0.654\"},{\"0\":\"GPT-4, Rubric 2; Human\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"81.8%\",\"4\":\"0.221\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"65.6%\",\"4\":\"0.538\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"79.5%\",\"4\":\"0.589\"},{\"0\":\"GPT-4, Rubric 1; GPT-4, Rubric 2\",\"1\":\"U\",\"2\":\"E1\",\"3\":\"91.1%\",\"4\":\"0.611\"},{\"0\":\"\",\"1\":\"V\",\"2\":\"E1 + .5*E2\",\"3\":\"76.0%\",\"4\":\"0.705\"},{\"0\":\"\",\"1\":\"Z\",\"2\":\"E1 + E2\",\"3\":\"82.4%\",\"4\":\"0.680\"}]'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda element: element['source']=='camelot',all_tables))[10]['table']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6cd1cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table': {'table_number': 22,\n",
       "  'page_number': 17,\n",
       "  'data': '[{\"0\":\"Basic Skill\",\"1\":\"U (\\\\nU\",\"2\":\"V\",\"3\":\"\",\"4\":\"Z (\\\\nZ\"},{\"0\":\"\",\"1\":\"std err)\",\"2\":\"\",\"3\":\"(std err)\",\"4\":\"std err)\"},{\"0\":\"\",\"1\":\"\",\"2\":\"All skill importance scores are normalized to be between 0 and 1.\",\"3\":\"\",\"4\":\"\"},{\"0\":\"Constant\",\"1\":\"0.082***\",\"2\":\"\",\"3\":\"-0.112***\",\"4\":\"0.300***\"},{\"0\":\"\",\"1\":\"(0.011)\",\"2\":\"\",\"3\":\"(0.011)\",\"4\":\"(0.057)\"},{\"0\":\"Active Listening\",\"1\":\"0.128**\",\"2\":\"\",\"3\":\"0.214***\",\"4\":\"0.449***\"},{\"0\":\"\",\"1\":\"(0.047)\",\"2\":\"\",\"3\":\"(0.043)\",\"4\":\"(0.027)\"},{\"0\":\"Mathematics\",\"1\":\"-0.127***\",\"2\":\"\",\"3\":\"0.161***\",\"4\":\"0.787***\"},{\"0\":\"\",\"1\":\"(0.026)\",\"2\":\"\",\"3\":\"(0.021)\",\"4\":\"(0.049)\"},{\"0\":\"Reading Comprehension\",\"1\":\"0.153***\",\"2\":\"\",\"3\":\"0.470***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.041)\",\"2\":\"\",\"3\":\"(0.037)\",\"4\":\"(0.017)\"},{\"0\":\"Science\",\"1\":\"-0.114***\",\"2\":\"\",\"3\":\"-0.230***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.014)\",\"2\":\"\",\"3\":\"(0.012)\",\"4\":\"(0.017)\"},{\"0\":\"Speaking\",\"1\":\"-0.028\",\"2\":\"\",\"3\":\"0.133***\",\"4\":\"0.294***\"},{\"0\":\"\",\"1\":\"(0.039)\",\"2\":\"\",\"3\":\"(0.033)\",\"4\":\"(0.042)\"},{\"0\":\"Writing\",\"1\":\"0.368***\",\"2\":\"\",\"3\":\"0.467***\",\"4\":\"0.566***\"},{\"0\":\"\",\"1\":\"(0.042)\",\"2\":\"\",\"3\":\"(0.037)\",\"4\":\"(0.047)\"},{\"0\":\"Active Learning\",\"1\":\"-0.157***\",\"2\":\"\",\"3\":\"-0.065**\",\"4\":\"0.028\"},{\"0\":\"\",\"1\":\"(0.027)\",\"2\":\"\",\"3\":\"(0.024)\",\"4\":\"(0.032)\"},{\"0\":\"Critical Thinking\",\"1\":\"-0.264***\",\"2\":\"\",\"3\":\"-0.196***\",\"4\":\"-0.129**\"},{\"0\":\"\",\"1\":\"(0.036)\",\"2\":\"\",\"3\":\"(0.033)\",\"4\":\"(0.042)\"},{\"0\":\"Learning Strategies\",\"1\":\"-0.072*\",\"2\":\"\",\"3\":\"-0.209***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.028)\",\"2\":\"\",\"3\":\"(0.025)\",\"4\":\"(0.034)\"},{\"0\":\"Monitoring\",\"1\":\"-0.067**\",\"2\":\"\",\"3\":\"-0.149***\",\"4\":\"-0.232***\"},{\"0\":\"\",\"1\":\"(0.023)\",\"2\":\"\",\"3\":\"0.020)\",\"4\":\"(0.026)\"},{\"0\":\"Programming\",\"1\":\"0.637***\",\"2\":\"\",\"3\":\"0.623***\",\"4\":\"0.609***\"},{\"0\":\"\",\"1\":\"(0.030)\",\"2\":\"\",\"3\":\"(0.022)\",\"4\":\"(0.024)\"}]'},\n",
       " 'source': 'camelot'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda element: element['source']=='camelot',all_tables))[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Skill</td>\n",
       "      <td>U (\\nU</td>\n",
       "      <td>V</td>\n",
       "      <td></td>\n",
       "      <td>Z (\\nZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>std err)</td>\n",
       "      <td></td>\n",
       "      <td>(std err)</td>\n",
       "      <td>std err)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All skill importance scores are normalized to ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Constant</td>\n",
       "      <td>0.082***</td>\n",
       "      <td></td>\n",
       "      <td>-0.112***</td>\n",
       "      <td>0.300***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>(0.011)</td>\n",
       "      <td></td>\n",
       "      <td>(0.011)</td>\n",
       "      <td>(0.057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Active Listening</td>\n",
       "      <td>0.128**</td>\n",
       "      <td></td>\n",
       "      <td>0.214***</td>\n",
       "      <td>0.449***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>(0.047)</td>\n",
       "      <td></td>\n",
       "      <td>(0.043)</td>\n",
       "      <td>(0.027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>-0.127***</td>\n",
       "      <td></td>\n",
       "      <td>0.161***</td>\n",
       "      <td>0.787***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>(0.026)</td>\n",
       "      <td></td>\n",
       "      <td>(0.021)</td>\n",
       "      <td>(0.049)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reading Comprehension</td>\n",
       "      <td>0.153***</td>\n",
       "      <td></td>\n",
       "      <td>0.470***</td>\n",
       "      <td>-0.346***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>(0.041)</td>\n",
       "      <td></td>\n",
       "      <td>(0.037)</td>\n",
       "      <td>(0.017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Science</td>\n",
       "      <td>-0.114***</td>\n",
       "      <td></td>\n",
       "      <td>-0.230***</td>\n",
       "      <td>-0.346***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>(0.014)</td>\n",
       "      <td></td>\n",
       "      <td>(0.012)</td>\n",
       "      <td>(0.017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Speaking</td>\n",
       "      <td>-0.028</td>\n",
       "      <td></td>\n",
       "      <td>0.133***</td>\n",
       "      <td>0.294***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>(0.039)</td>\n",
       "      <td></td>\n",
       "      <td>(0.033)</td>\n",
       "      <td>(0.042)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Writing</td>\n",
       "      <td>0.368***</td>\n",
       "      <td></td>\n",
       "      <td>0.467***</td>\n",
       "      <td>0.566***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>(0.042)</td>\n",
       "      <td></td>\n",
       "      <td>(0.037)</td>\n",
       "      <td>(0.047)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Active Learning</td>\n",
       "      <td>-0.157***</td>\n",
       "      <td></td>\n",
       "      <td>-0.065**</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>(0.027)</td>\n",
       "      <td></td>\n",
       "      <td>(0.024)</td>\n",
       "      <td>(0.032)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Critical Thinking</td>\n",
       "      <td>-0.264***</td>\n",
       "      <td></td>\n",
       "      <td>-0.196***</td>\n",
       "      <td>-0.129**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>(0.036)</td>\n",
       "      <td></td>\n",
       "      <td>(0.033)</td>\n",
       "      <td>(0.042)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Learning Strategies</td>\n",
       "      <td>-0.072*</td>\n",
       "      <td></td>\n",
       "      <td>-0.209***</td>\n",
       "      <td>-0.346***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>(0.028)</td>\n",
       "      <td></td>\n",
       "      <td>(0.025)</td>\n",
       "      <td>(0.034)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monitoring</td>\n",
       "      <td>-0.067**</td>\n",
       "      <td></td>\n",
       "      <td>-0.149***</td>\n",
       "      <td>-0.232***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>(0.023)</td>\n",
       "      <td></td>\n",
       "      <td>0.020)</td>\n",
       "      <td>(0.026)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Programming</td>\n",
       "      <td>0.637***</td>\n",
       "      <td></td>\n",
       "      <td>0.623***</td>\n",
       "      <td>0.609***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>(0.030)</td>\n",
       "      <td></td>\n",
       "      <td>(0.022)</td>\n",
       "      <td>(0.024)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0          1  \\\n",
       "0             Basic Skill     U (\\nU   \n",
       "1                           std err)   \n",
       "2                                      \n",
       "3                Constant   0.082***   \n",
       "4                            (0.011)   \n",
       "5        Active Listening    0.128**   \n",
       "6                            (0.047)   \n",
       "7             Mathematics  -0.127***   \n",
       "8                            (0.026)   \n",
       "9   Reading Comprehension   0.153***   \n",
       "10                           (0.041)   \n",
       "11                Science  -0.114***   \n",
       "12                           (0.014)   \n",
       "13               Speaking     -0.028   \n",
       "14                           (0.039)   \n",
       "15                Writing   0.368***   \n",
       "16                           (0.042)   \n",
       "17        Active Learning  -0.157***   \n",
       "18                           (0.027)   \n",
       "19      Critical Thinking  -0.264***   \n",
       "20                           (0.036)   \n",
       "21    Learning Strategies    -0.072*   \n",
       "22                           (0.028)   \n",
       "23             Monitoring   -0.067**   \n",
       "24                           (0.023)   \n",
       "25            Programming   0.637***   \n",
       "26                           (0.030)   \n",
       "\n",
       "                                                    2          3          4  \n",
       "0                                                   V                Z (\\nZ  \n",
       "1                                                      (std err)   std err)  \n",
       "2   All skill importance scores are normalized to ...                        \n",
       "3                                                      -0.112***   0.300***  \n",
       "4                                                        (0.011)    (0.057)  \n",
       "5                                                       0.214***   0.449***  \n",
       "6                                                        (0.043)    (0.027)  \n",
       "7                                                       0.161***   0.787***  \n",
       "8                                                        (0.021)    (0.049)  \n",
       "9                                                       0.470***  -0.346***  \n",
       "10                                                       (0.037)    (0.017)  \n",
       "11                                                     -0.230***  -0.346***  \n",
       "12                                                       (0.012)    (0.017)  \n",
       "13                                                      0.133***   0.294***  \n",
       "14                                                       (0.033)    (0.042)  \n",
       "15                                                      0.467***   0.566***  \n",
       "16                                                       (0.037)    (0.047)  \n",
       "17                                                      -0.065**      0.028  \n",
       "18                                                       (0.024)    (0.032)  \n",
       "19                                                     -0.196***   -0.129**  \n",
       "20                                                       (0.033)    (0.042)  \n",
       "21                                                     -0.209***  -0.346***  \n",
       "22                                                       (0.025)    (0.034)  \n",
       "23                                                     -0.149***  -0.232***  \n",
       "24                                                        0.020)    (0.026)  \n",
       "25                                                      0.623***   0.609***  \n",
       "26                                                       (0.022)    (0.024)  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = list(filter(lambda element: element['source']=='camelot',all_tables))[22]['table']['data']\n",
    "json_data = json.loads(test_case)\n",
    "df = pd.DataFrame(json_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cb78e159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job</td>\n",
       "      <td>Preparation</td>\n",
       "      <td>Education</td>\n",
       "      <td>Example Occupations</td>\n",
       "      <td>Median</td>\n",
       "      <td>Tot Emp</td>\n",
       "      <td>HUUU</td>\n",
       "      <td>MUUU</td>\n",
       "      <td>HVVV</td>\n",
       "      <td>MVVV</td>\n",
       "      <td>HZZZ</td>\n",
       "      <td>MZZZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zone</td>\n",
       "      <td>Required</td>\n",
       "      <td>Required</td>\n",
       "      <td></td>\n",
       "      <td>Income</td>\n",
       "      <td>(000s)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>None or little</td>\n",
       "      <td>High school</td>\n",
       "      <td>Food preparation workers,</td>\n",
       "      <td>$30,230</td>\n",
       "      <td>13,100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>(0-3 months)</td>\n",
       "      <td>diploma or GED</td>\n",
       "      <td>dishwashers, ﬂoor sanders</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(otional)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Some (3-12</td>\n",
       "      <td>High school</td>\n",
       "      <td>Orderlies, customer</td>\n",
       "      <td>$38,215</td>\n",
       "      <td>73,962</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>months)</td>\n",
       "      <td>diploma</td>\n",
       "      <td>service representatives,</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>tellers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Medium (1-2</td>\n",
       "      <td>Vocational school,</td>\n",
       "      <td>Electricians, barbers,</td>\n",
       "      <td>$54,815</td>\n",
       "      <td>37,881</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>years)</td>\n",
       "      <td>on-the-job training,</td>\n",
       "      <td>medical assistants</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>or associate’s</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>degree</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Considerable</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Database administrators,</td>\n",
       "      <td>$77,345</td>\n",
       "      <td>56,833</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>(2-4 years)</td>\n",
       "      <td></td>\n",
       "      <td>graphic designers, cost</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>estimators</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Extensive (4+</td>\n",
       "      <td>Master’s degree or</td>\n",
       "      <td>Pharmacists, lawyers,</td>\n",
       "      <td>$81,980</td>\n",
       "      <td>21,221</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>years)</td>\n",
       "      <td>higher</td>\n",
       "      <td>astronomers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0               1                     2                          3  \\\n",
       "1    Job     Preparation             Education        Example Occupations   \n",
       "2   Zone        Required              Required                              \n",
       "3      1  None or little           High school  Food preparation workers,   \n",
       "4           (0-3 months)        diploma or GED  dishwashers, ﬂoor sanders   \n",
       "5                                    (otional)                              \n",
       "6      2      Some (3-12           High school        Orderlies, customer   \n",
       "7                months)               diploma   service representatives,   \n",
       "8                                                                 tellers   \n",
       "9      3     Medium (1-2    Vocational school,     Electricians, barbers,   \n",
       "10                years)  on-the-job training,         medical assistants   \n",
       "11                              or associate’s                              \n",
       "12                                      degree                              \n",
       "13     4    Considerable     Bachelor’s degree   Database administrators,   \n",
       "14           (2-4 years)                          graphic designers, cost   \n",
       "15                                                             estimators   \n",
       "16     5   Extensive (4+    Master’s degree or      Pharmacists, lawyers,   \n",
       "17                years)                higher                astronomers   \n",
       "\n",
       "          4        5     6     7     8     9    10    11  \n",
       "1    Median  Tot Emp  HUUU  MUUU  HVVV  MVVV  HZZZ  MZZZ  \n",
       "2    Income   (000s)                                      \n",
       "3   $30,230   13,100  0.03  0.04  0.06  0.06  0.09  0.08  \n",
       "4                                                         \n",
       "5                                                         \n",
       "6   $38,215   73,962  0.07  0.12  0.16  0.20  0.24  0.27  \n",
       "7                                                         \n",
       "8                                                         \n",
       "9   $54,815   37,881  0.11  0.14  0.26  0.32  0.41  0.51  \n",
       "10                                                        \n",
       "11                                                        \n",
       "12                                                        \n",
       "13  $77,345   56,833  0.23  0.18  0.47  0.51  0.71  0.85  \n",
       "14                                                        \n",
       "15                                                        \n",
       "16  $81,980   21,221  0.23  0.13  0.43  0.45  0.63  0.76  \n",
       "17                                                        "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = list(filter(lambda element: element['source']=='camelot',all_tables))[23]['table']['data']\n",
    "json_data = json.loads(test_case)\n",
    "df = pd.DataFrame(json_data, columns=None)\n",
    "df.drop(df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e30ef95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"0\":\"Basic Skill\",\"1\":\"U (\\\\nU\",\"2\":\"V\",\"3\":\"\",\"4\":\"Z (\\\\nZ\"},{\"0\":\"\",\"1\":\"std err)\",\"2\":\"\",\"3\":\"(std err)\",\"4\":\"std err)\"},{\"0\":\"\",\"1\":\"\",\"2\":\"All skill importance scores are normalized to be between 0 and 1.\",\"3\":\"\",\"4\":\"\"},{\"0\":\"Constant\",\"1\":\"0.082***\",\"2\":\"\",\"3\":\"-0.112***\",\"4\":\"0.300***\"},{\"0\":\"\",\"1\":\"(0.011)\",\"2\":\"\",\"3\":\"(0.011)\",\"4\":\"(0.057)\"},{\"0\":\"Active Listening\",\"1\":\"0.128**\",\"2\":\"\",\"3\":\"0.214***\",\"4\":\"0.449***\"},{\"0\":\"\",\"1\":\"(0.047)\",\"2\":\"\",\"3\":\"(0.043)\",\"4\":\"(0.027)\"},{\"0\":\"Mathematics\",\"1\":\"-0.127***\",\"2\":\"\",\"3\":\"0.161***\",\"4\":\"0.787***\"},{\"0\":\"\",\"1\":\"(0.026)\",\"2\":\"\",\"3\":\"(0.021)\",\"4\":\"(0.049)\"},{\"0\":\"Reading Comprehension\",\"1\":\"0.153***\",\"2\":\"\",\"3\":\"0.470***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.041)\",\"2\":\"\",\"3\":\"(0.037)\",\"4\":\"(0.017)\"},{\"0\":\"Science\",\"1\":\"-0.114***\",\"2\":\"\",\"3\":\"-0.230***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.014)\",\"2\":\"\",\"3\":\"(0.012)\",\"4\":\"(0.017)\"},{\"0\":\"Speaking\",\"1\":\"-0.028\",\"2\":\"\",\"3\":\"0.133***\",\"4\":\"0.294***\"},{\"0\":\"\",\"1\":\"(0.039)\",\"2\":\"\",\"3\":\"(0.033)\",\"4\":\"(0.042)\"},{\"0\":\"Writing\",\"1\":\"0.368***\",\"2\":\"\",\"3\":\"0.467***\",\"4\":\"0.566***\"},{\"0\":\"\",\"1\":\"(0.042)\",\"2\":\"\",\"3\":\"(0.037)\",\"4\":\"(0.047)\"},{\"0\":\"Active Learning\",\"1\":\"-0.157***\",\"2\":\"\",\"3\":\"-0.065**\",\"4\":\"0.028\"},{\"0\":\"\",\"1\":\"(0.027)\",\"2\":\"\",\"3\":\"(0.024)\",\"4\":\"(0.032)\"},{\"0\":\"Critical Thinking\",\"1\":\"-0.264***\",\"2\":\"\",\"3\":\"-0.196***\",\"4\":\"-0.129**\"},{\"0\":\"\",\"1\":\"(0.036)\",\"2\":\"\",\"3\":\"(0.033)\",\"4\":\"(0.042)\"},{\"0\":\"Learning Strategies\",\"1\":\"-0.072*\",\"2\":\"\",\"3\":\"-0.209***\",\"4\":\"-0.346***\"},{\"0\":\"\",\"1\":\"(0.028)\",\"2\":\"\",\"3\":\"(0.025)\",\"4\":\"(0.034)\"},{\"0\":\"Monitoring\",\"1\":\"-0.067**\",\"2\":\"\",\"3\":\"-0.149***\",\"4\":\"-0.232***\"},{\"0\":\"\",\"1\":\"(0.023)\",\"2\":\"\",\"3\":\"0.020)\",\"4\":\"(0.026)\"},{\"0\":\"Programming\",\"1\":\"0.637***\",\"2\":\"\",\"3\":\"0.623***\",\"4\":\"0.609***\"},{\"0\":\"\",\"1\":\"(0.030)\",\"2\":\"\",\"3\":\"(0.022)\",\"4\":\"(0.024)\"}]'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda element: element['source']=='camelot',all_tables))[22]['table']['data']"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
