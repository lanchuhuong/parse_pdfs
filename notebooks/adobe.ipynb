{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46ec6ec",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec38d2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Collecting pdfservices-sdk\n",
       "  Downloading pdfservices_sdk-2.3.1-py3-none-any.whl (85 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/85.6 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 3.1 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: cffi==1.15.1 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (1.15.1)\n",
       "Collecting polling2==0.5.0\n",
       "  Downloading polling2-0.5.0-py2.py3-none-any.whl (6.4 kB)\n",
       "Collecting multipart==0.2.4\n",
       "  Downloading multipart-0.2.4-py3-none-any.whl (7.4 kB)\n",
       "Collecting Pygments==2.14.0\n",
       "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/1.1 MB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 45.8 MB/s eta 0:00:00\n",
       "\u001b[?25hCollecting build==0.9.0\n",
       "  Downloading build-0.9.0-py3-none-any.whl (17 kB)\n",
       "Requirement already satisfied: pycparser==2.21 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (2.21)\n",
       "Collecting polling==0.3.2\n",
       "  Downloading polling-0.3.2.tar.gz (5.2 kB)\n",
       "  Preparing metadata (setup.py): started\n",
       "  Preparing metadata (setup.py): finished with status 'done'\n",
       "Collecting packaging==21.3\n",
       "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/40.8 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 kB 4.1 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: PyYAML==6.0 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (6.0)\n",
       "Collecting certifi==2022.12.7\n",
       "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/155.3 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 19.7 MB/s eta 0:00:00\n",
       "\u001b[?25hCollecting requests==2.27.1\n",
       "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/63.1 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 10.0 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: six==1.16.0 in /usr/lib/python3/dist-packages (from pdfservices-sdk) (1.16.0)\n",
       "Collecting pep517==0.13.0\n",
       "  Downloading pep517-0.13.0-py3-none-any.whl (18 kB)\n",
       "Collecting urllib3==1.26.13\n",
       "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/140.6 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.6/140.6 kB 22.3 MB/s eta 0:00:00\n",
       "\u001b[?25hCollecting PyJWT==2.4.0\n",
       "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
       "Collecting requests-toolbelt==0.10.1\n",
       "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/54.5 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 8.2 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: pyparsing==3.0.9 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (3.0.9)\n",
       "Collecting cryptography==3.4.6\n",
       "  Downloading cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/3.2 MB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 3.2/3.2 MB 130.2 MB/s eta 0:00:01\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 73.0 MB/s eta 0:00:00\n",
       "\u001b[?25hCollecting toml==0.10.2\n",
       "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
       "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests==2.27.1->pdfservices-sdk) (3.4)\n",
       "Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from requests==2.27.1->pdfservices-sdk) (2.0.4)\n",
       "Building wheels for collected packages: polling\n",
       "  Building wheel for polling (setup.py): started\n",
       "  Building wheel for polling (setup.py): finished with status 'done'\n",
       "  Created wheel for polling: filename=polling-0.3.2-py3-none-any.whl size=4125 sha256=9c5d59b5981997175fff79c14eb764b12d35b9a979fde2bc7f787f9a6ab2bca6\n",
       "  Stored in directory: /root/.cache/pip/wheels/92/b9/62/cedeba300a4e1a41f7f707add2bbfda8c0dea1f682fed11ab1\n",
       "Successfully built polling\n",
       "Installing collected packages: polling2, polling, multipart, urllib3, toml, PyJWT, Pygments, pep517, packaging, certifi, requests, cryptography, build, requests-toolbelt, pdfservices-sdk\n",
       "  Attempting uninstall: urllib3\n",
       "    Found existing installation: urllib3 1.26.16\n",
       "    Not uninstalling urllib3 at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
       "  Attempting uninstall: PyJWT\n",
       "    Found existing installation: PyJWT 2.3.0\n",
       "    Not uninstalling pyjwt at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'PyJWT'. No files were found to uninstall.\n",
       "  Attempting uninstall: Pygments\n",
       "    Found existing installation: Pygments 2.15.1\n",
       "    Not uninstalling pygments at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'Pygments'. No files were found to uninstall.\n",
       "  Attempting uninstall: packaging\n",
       "    Found existing installation: packaging 23.2\n",
       "    Not uninstalling packaging at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'packaging'. No files were found to uninstall.\n",
       "  Attempting uninstall: certifi\n",
       "    Found existing installation: certifi 2023.7.22\n",
       "    Not uninstalling certifi at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'certifi'. No files were found to uninstall.\n",
       "  Attempting uninstall: requests\n",
       "    Found existing installation: requests 2.31.0\n",
       "    Not uninstalling requests at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'requests'. No files were found to uninstall.\n",
       "  Attempting uninstall: cryptography\n",
       "    Found existing installation: cryptography 41.0.3\n",
       "    Not uninstalling cryptography at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'cryptography'. No files were found to uninstall.\n",
       "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
       "petastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\n",
       "databricks-feature-engineering 0.3.0 requires pyspark<4,>=3.1.2, which is not installed.\n",
       "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.24.1 which is incompatible.\n",
       "langchain-core 0.1.23 requires packaging<24.0,>=23.2, but you have packaging 21.3 which is incompatible.\n",
       "databricks-sdk 0.20.0 requires requests<3,>=2.28.1, but you have requests 2.27.1 which is incompatible.\n",
       "black 23.3.0 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\n",
       "Successfully installed PyJWT-2.4.0 Pygments-2.14.0 build-0.9.0 certifi-2022.12.7 cryptography-3.4.6 multipart-0.2.4 packaging-21.3 pdfservices-sdk-2.3.1 pep517-0.13.0 polling-0.3.2 polling2-0.5.0 requests-2.27.1 requests-toolbelt-0.10.1 toml-0.10.2 urllib3-1.26.13\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Collecting openpyxl\n",
       "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/250.0 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 245.8/250.0 kB 9.0 MB/s eta 0:00:01\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250.0/250.0 kB 7.0 MB/s eta 0:00:00\n",
       "\u001b[?25hCollecting et-xmlfile\n",
       "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
       "Installing collected packages: et-xmlfile, openpyxl\n",
       "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Collecting langchain==0.0.278\n",
       "  Downloading langchain-0.0.278-py3-none-any.whl (1.6 MB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/1.6 MB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.3/1.6 MB 10.7 MB/s eta 0:00:01\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 25.4 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from langchain==0.0.278) (2.27.1)\n",
       "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages (from langchain==0.0.278) (2.0.29)\n",
       "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /databricks/python3/lib/python3.11/site-packages (from langchain==0.0.278) (0.0.87)\n",
       "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain==0.0.278) (8.2.2)\n",
       "Requirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain==0.0.278) (6.0)\n",
       "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.11/site-packages (from langchain==0.0.278) (3.8.5)\n",
       "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
       "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
       "Requirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain==0.0.278) (1.10.6)\n",
       "Requirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain==0.0.278) (1.23.5)\n",
       "Collecting numexpr<3.0.0,>=2.8.4\n",
       "  Downloading numexpr-2.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/378.3 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 378.3/378.3 kB 26.1 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.278) (6.0.2)\n",
       "Requirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.278) (1.3.3)\n",
       "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.278) (4.0.2)\n",
       "Requirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.278) (1.8.1)\n",
       "Requirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.278) (22.1.0)\n",
       "Requirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.278) (1.2.0)\n",
       "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.278) (2.0.4)\n",
       "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.278) (0.9.0)\n",
       "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.278) (3.21.1)\n",
       "Requirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.0.278) (4.7.1)\n",
       "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.278) (1.26.13)\n",
       "Requirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.278) (2022.12.7)\n",
       "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.278) (3.4)\n",
       "Requirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.278) (2.0.1)\n",
       "Requirement already satisfied: packaging>=17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.278) (21.3)\n",
       "Requirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.278) (0.4.3)\n",
       "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.11/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.278) (3.0.9)\n",
       "Installing collected packages: numexpr, dataclasses-json, langchain\n",
       "  Attempting uninstall: dataclasses-json\n",
       "    Found existing installation: dataclasses-json 0.6.4\n",
       "    Not uninstalling dataclasses-json at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'dataclasses-json'. No files were found to uninstall.\n",
       "  Attempting uninstall: langchain\n",
       "    Found existing installation: langchain 0.1.3\n",
       "    Not uninstalling langchain at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'langchain'. No files were found to uninstall.\n",
       "Successfully installed dataclasses-json-0.5.14 langchain-0.0.278 numexpr-2.10.0\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Collecting langchain-core==0.0.11\n",
       "  Downloading langchain_core-0.0.11-py3-none-any.whl (181 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/181.4 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.4/181.4 kB 5.5 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.11/site-packages (from langchain-core==0.0.11) (1.33)\n",
       "Requirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain-core==0.0.11) (1.10.6)\n",
       "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /databricks/python3/lib/python3.11/site-packages (from langchain-core==0.0.11) (0.0.87)\n",
       "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain-core==0.0.11) (8.2.2)\n",
       "Requirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.0.11) (2.4)\n",
       "Requirement already satisfied: requests<3,>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from langsmith<0.1.0,>=0.0.63->langchain-core==0.0.11) (2.27.1)\n",
       "Requirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core==0.0.11) (4.7.1)\n",
       "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.1.0,>=0.0.63->langchain-core==0.0.11) (1.26.13)\n",
       "Requirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.1.0,>=0.0.63->langchain-core==0.0.11) (2022.12.7)\n",
       "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.1.0,>=0.0.63->langchain-core==0.0.11) (3.4)\n",
       "Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.1.0,>=0.0.63->langchain-core==0.0.11) (2.0.4)\n",
       "Installing collected packages: langchain-core\n",
       "  Attempting uninstall: langchain-core\n",
       "    Found existing installation: langchain-core 0.1.23\n",
       "    Not uninstalling langchain-core at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'langchain-core'. No files were found to uninstall.\n",
       "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
       "langchain-community 0.0.20 requires langchain-core<0.2,>=0.1.21, but you have langchain-core 0.0.11 which is incompatible.\n",
       "Successfully installed langchain-core-0.0.11\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Requirement already satisfied: pdfservices-sdk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (2.3.1)\n",
       "Requirement already satisfied: cffi==1.15.1 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (1.15.1)\n",
       "Requirement already satisfied: polling2==0.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (0.5.0)\n",
       "Requirement already satisfied: multipart==0.2.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (0.2.4)\n",
       "Requirement already satisfied: Pygments==2.14.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (2.14.0)\n",
       "Requirement already satisfied: build==0.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (0.9.0)\n",
       "Requirement already satisfied: pycparser==2.21 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (2.21)\n",
       "Requirement already satisfied: polling==0.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (0.3.2)\n",
       "Requirement already satisfied: packaging==21.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (21.3)\n",
       "Requirement already satisfied: PyYAML==6.0 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (6.0)\n",
       "Requirement already satisfied: certifi==2022.12.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (2022.12.7)\n",
       "Requirement already satisfied: requests==2.27.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (2.27.1)\n",
       "Requirement already satisfied: six==1.16.0 in /usr/lib/python3/dist-packages (from pdfservices-sdk) (1.16.0)\n",
       "Requirement already satisfied: pep517==0.13.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (0.13.0)\n",
       "Requirement already satisfied: urllib3==1.26.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (1.26.13)\n",
       "Requirement already satisfied: PyJWT==2.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (2.4.0)\n",
       "Requirement already satisfied: requests-toolbelt==0.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (0.10.1)\n",
       "Requirement already satisfied: pyparsing==3.0.9 in /databricks/python3/lib/python3.11/site-packages (from pdfservices-sdk) (3.0.9)\n",
       "Requirement already satisfied: cryptography==3.4.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (3.4.6)\n",
       "Requirement already satisfied: toml==0.10.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from pdfservices-sdk) (0.10.2)\n",
       "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests==2.27.1->pdfservices-sdk) (3.4)\n",
       "Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from requests==2.27.1->pdfservices-sdk) (2.0.4)\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\n",
       "Collecting openai==0.27.8\n",
       "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/73.6 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.6/73.6 kB 2.6 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: requests>=2.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from openai==0.27.8) (2.27.1)\n",
       "Requirement already satisfied: aiohttp in /databricks/python3/lib/python3.11/site-packages (from openai==0.27.8) (3.8.5)\n",
       "Requirement already satisfied: tqdm in /databricks/python3/lib/python3.11/site-packages (from openai==0.27.8) (4.65.0)\n",
       "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8) (1.26.13)\n",
       "Requirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8) (2022.12.7)\n",
       "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8) (3.4)\n",
       "Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.8) (2.0.4)\n",
       "Requirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8) (6.0.2)\n",
       "Requirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8) (1.3.3)\n",
       "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8) (4.0.2)\n",
       "Requirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8) (1.8.1)\n",
       "Requirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8) (22.1.0)\n",
       "Requirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.11/site-packages (from aiohttp->openai==0.27.8) (1.2.0)\n",
       "Installing collected packages: openai\n",
       "  Attempting uninstall: openai\n",
       "    Found existing installation: openai 1.9.0\n",
       "    Not uninstalling openai at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f5595c9e-6686-402b-8ffe-0f255c9d18b3\n",
       "    Can't uninstall 'openai'. No files were found to uninstall.\n",
       "Successfully installed openai-0.27.8\n",
       "Note: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "!pip install pdfservices-sdk\n",
    "!pip install openpyxl\n",
    "!pip install langchain==0.0.278\n",
    "!pip install langchain-core==0.0.11\n",
    "!pip install pdfservices-sdk\n",
    "!pip install openai==0.27.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f1ef4d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from adobe.pdfservices.operation.auth.credentials import Credentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.execution_context import ExecutionContext\n",
    "from adobe.pdfservices.operation.io.file_ref import FileRef\n",
    "from adobe.pdfservices.operation.pdfops.extract_pdf_operation import ExtractPDFOperation\n",
    "from adobe.pdfservices.operation.pdfops.options.extractpdf.extract_pdf_options import ExtractPDFOptions\n",
    "from adobe.pdfservices.operation.pdfops.options.extractpdf.extract_element_type import ExtractElementType\n",
    "from adobe.pdfservices.operation.pdfops.options.extractpdf.extract_renditions_element_type import \\\n",
    "    ExtractRenditionsElementType\n",
    "import os.path\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import openpyxl\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36fc04b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_dict_xlsx(outputzipextract, xlsx_file):\n",
    "    \"\"\"\n",
    "    Function to read excel output from adobe API\n",
    "    \"\"\"\n",
    "    # Read excel\n",
    "    df = pd.read_excel(os.path.join(\n",
    "        outputzipextract, xlsx_file), sheet_name='Sheet1', engine='openpyxl')\n",
    "    \n",
    "    # Clean df\n",
    "    df.columns = [re.sub(r\"_x([0-9a-fA-F]{4})_\", \"\", col) for col in df.columns]\n",
    "    df = df.replace({r\"_x([0-9a-fA-F]{4})_\": \"\"}, regex=True)\n",
    "\n",
    "    # Convert df to string\n",
    "    data_dict = df.to_dict(orient='records')\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee9a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client_id = os.getenv(\"ADOBE_CLIENT_ID\")\n",
    "client_secret = os.getenv('ADOBE_CLIENT_SECRET')\n",
    "client_id = 'cc9a3889ee33401c98fc8e22b31a43e6'\n",
    "client_secret = 'p8e-gUADUlOvUimilFf3NzypTzT9aJPNEsP2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcd7d1f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def adobeLoader(input_pdf, output_zip_path,client_id, client_secret):\n",
    "    \"\"\"\n",
    "    Function to run adobe API and create output zip file\n",
    "    \"\"\"\n",
    "    # Initial setup, create credentials instance.\n",
    "    credentials = Credentials.service_principal_credentials_builder() \\\n",
    "        .with_client_id(client_id) \\\n",
    "        .with_client_secret(client_secret) \\\n",
    "        .build()\n",
    "\n",
    "    # Create an ExecutionContext using credentials and create a new operation instance.\n",
    "    execution_context = ExecutionContext.create(credentials)\n",
    "    extract_pdf_operation = ExtractPDFOperation.create_new()\n",
    "\n",
    "    # Set operation input from a source file.\n",
    "    source = FileRef.create_from_local_file(input_pdf)\n",
    "    extract_pdf_operation.set_input(source)\n",
    "\n",
    "    # Build ExtractPDF options and set them into the operation\n",
    "    extract_pdf_options: ExtractPDFOptions = ExtractPDFOptions.builder() \\\n",
    "        .with_elements_to_extract([ExtractElementType.TEXT, ExtractElementType.TABLES]) \\\n",
    "        .with_elements_to_extract_renditions([ExtractRenditionsElementType.TABLES,\n",
    "                                                ExtractRenditionsElementType.FIGURES]) \\\n",
    "        .build()\n",
    "    extract_pdf_operation.set_options(extract_pdf_options)\n",
    "\n",
    "    # Execute the operation.\n",
    "    result: FileRef = extract_pdf_operation.execute(execution_context)\n",
    "\n",
    "    # Save result to output path\n",
    "    if os.path.exists(output_zip_path):\n",
    "        os.remove(output_zip_path)\n",
    "    result.save_as(output_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32468fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_file_adobe(output_zip_path, output_zipextract_folder):\n",
    "    \"\"\"\n",
    "    Function to extract text and table from adobe output zip file\n",
    "    Read and Process JSON: Opens the structuredData.json file which contains the extracted data in a structured format.\n",
    "    Data Extraction: Iterates through the elements in the JSON file, collecting text\n",
    "    directly and processing tables by referring to their file paths in the Excel\n",
    "    format. Table Processing via get_dict_xlsx: When it encounters a table, it uses\n",
    "    the file path to call get_dict_xlsx, which reads the Excel file, cleans the\n",
    "    data, and converts it to a dictionary format. This dictionary is then converted\n",
    "    into a JSON string and added to the DataFrame.\n",
    "    \"\"\"    \n",
    "    json_strings = []\n",
    "    try:\n",
    "        print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} unzip file\")\n",
    "        # Open the ZIP file\n",
    "        with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:\n",
    "            # Extract all the contents of the ZIP file to the current working directory\n",
    "            zip_ref.extractall(path=output_zipextract_folder)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing input: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} open json file\")\n",
    "        # Opening JSON file\n",
    "        with open(os.path.join(output_zipextract_folder, \"structuredData.json\")) as json_file:\n",
    "            data = json.load(json_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing output: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} extract text\")\n",
    "        dfs = pd.DataFrame()\n",
    "        page = ''\n",
    "        # Loop through elements in the document\n",
    "        for ele in data['elements']:\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            # Get element page\n",
    "            if ('Page' in ele.keys()):\n",
    "                page = ele['Page']\n",
    "\n",
    "            # Append table\n",
    "            if any(x in ele['Path'] for x in ['Table']):\n",
    "                if ('filePaths' in ele):\n",
    "                    if [s for s in ele['filePaths'] if 'xlsx' in s]:\n",
    "                        # Read excel table\n",
    "                        data_dict = get_dict_xlsx(output_zipextract_folder, ele['filePaths'][0])\n",
    "                        json_string = json.dumps(data_dict)\n",
    "                        json_strings.append(json_string)\n",
    "                        print (f\"the json string is: {json_string}\")\n",
    "                        df = pd.DataFrame({'text': json_string}, index=[0])\n",
    "                        \n",
    "\n",
    "            # Append text            \n",
    "            elif 'Text' in ele.keys():\n",
    "                df = pd.DataFrame({'text': ele['Text']}, index=[0])\n",
    "\n",
    "            # print(page)\n",
    "            df['page_number'] = page\n",
    "            dfs = pd.concat([dfs, df], axis=0)\n",
    "\n",
    "        dfs = dfs.reset_index(drop=True)\n",
    "\n",
    "        # Groupby page\n",
    "        dfs = dfs.groupby('page_number')['text'].apply(lambda x: '\\n'.join(x)).reset_index()\n",
    "    except Exception as e:\n",
    "        print('----Error: cannot extract text')\n",
    "        return None, None\n",
    "    return dfs, json_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9895d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-28 14:31:17 unzip file\n",
      "2024-04-28 14:31:17 open json file\n",
      "2024-04-28 14:31:17 extract text\n",
      "the json string is: [{\"Task ID \": \"14675 \", \"Occupation Title \": \"Computer Systems Engineers/Architects \", \"DWAs \": \"Monitor computer system performance to ensure proper operation. \", \"Task Description \": \"Monitor system operation to detect potential problems. \"}, {\"Task ID \": \"18310 \", \"Occupation Title \": \"Acute Care Nurses \", \"DWAs \": \"Operate diagnostic or therapeutic medical instruments or equipment. Prepare medical supplies or equipment for use. \", \"Task Description \": \"Set up, operate, or monitor invasive equipment and devices, such as colostomy or tracheotomy equipment, mechanical ventilators, catheters, gastrointestinal tubes, and central lines. \"}, {\"Task ID \": \"4668.0 \", \"Occupation Title \": \"Gambling Cage Workers \", \"DWAs \": \"Execute sales or other financial transactions. \", \"Task Description \": \"Cash checks and process credit card advances for patrons. \"}, {\"Task ID \": \"15709 \", \"Occupation Title \": \"Online Merchants \", \"DWAs \": \"Execute sales or other financial transactions. \", \"Task Description \": \"Deliver e-mail confirmation of completed transactions and shipment. \"}, {\"Task ID \": \"6529 \", \"Occupation Title \": \"Kindergarten Teachers, Except Special Education \", \"DWAs \": \"\\u2013 \", \"Task Description \": \"Involve parent volunteers and older students in children\\u2019s activities to facilitate involvement in focused, complex play. \"}, {\"Task ID \": \"6568 \", \"Occupation Title \": \"Elementary School Teachers, Except Special Education \", \"DWAs \": \"\\u2013 \", \"Task Description \": \"Involve parent volunteers and older students in children\\u2019s activities to facilitate involvement in focused, complex play. \"}]\n",
      "the json string is: [{\"Comparison \": \"GPT-4, Rubric 1; Human \", \"W \": \"U \", \"Weighting \": \"E1 \", \"Agreement \": \"80.8% \", \"Pearson\\u2019s \": \"0.223 \"}, {\"Comparison \": NaN, \"W \": \"V \", \"Weighting \": \"E1 + .5*E2 \", \"Agreement \": \"65.6% \", \"Pearson\\u2019s \": \"0.591 \"}, {\"Comparison \": NaN, \"W \": \"Z \", \"Weighting \": \"E1 + E2 \", \"Agreement \": \"82.1% \", \"Pearson\\u2019s \": \"0.654 \"}, {\"Comparison \": \"GPT-4, Rubric 2; Human \", \"W \": \"U \", \"Weighting \": \"E1 \", \"Agreement \": \"81.8% \", \"Pearson\\u2019s \": \"0.221 \"}, {\"Comparison \": NaN, \"W \": \"V \", \"Weighting \": \"E1 + .5*E2 \", \"Agreement \": \"65.6% \", \"Pearson\\u2019s \": \"0.538 \"}, {\"Comparison \": NaN, \"W \": \"Z \", \"Weighting \": \"E1 + E2 \", \"Agreement \": \"79.5% \", \"Pearson\\u2019s \": \"0.589 \"}, {\"Comparison \": \"GPT-4, Rubric 1; GPT-4, Rubric 2 \", \"W \": \"U \", \"Weighting \": \"E1 \", \"Agreement \": \"91.1% \", \"Pearson\\u2019s \": \"0.611 \"}, {\"Comparison \": NaN, \"W \": \"V \", \"Weighting \": \"E1 + .5*E2 \", \"Agreement \": \"76.0% \", \"Pearson\\u2019s \": \"0.705 \"}, {\"Comparison \": NaN, \"W \": \"Z \", \"Weighting \": \"E1 + E2 \", \"Agreement \": \"82.4% \", \"Pearson\\u2019s \": \"0.680 \"}]\n",
      "the json string is: [{\"Occupation Level Exposure \": NaN, \"Unnamed: 1\": \"Human \", \"Unnamed: 2\": NaN, \"Unnamed: 3\": \"GPT-4 \", \"Unnamed: 4\": NaN}, {\"Occupation Level Exposure \": NaN, \"Unnamed: 1\": \"mean \", \"Unnamed: 2\": \"std \", \"Unnamed: 3\": \"mean \", \"Unnamed: 4\": \"std \"}, {\"Occupation Level Exposure \": \"U \", \"Unnamed: 1\": \"0.14 \", \"Unnamed: 2\": \"0.14 \", \"Unnamed: 3\": \"0.14 \", \"Unnamed: 4\": \"0.16 \"}, {\"Occupation Level Exposure \": \"V \", \"Unnamed: 1\": \"0.30 \", \"Unnamed: 2\": \"0.21 \", \"Unnamed: 3\": \"0.34 \", \"Unnamed: 4\": \"0.22 \"}, {\"Occupation Level Exposure \": \"Z \", \"Unnamed: 1\": \"0.46 \", \"Unnamed: 2\": \"0.30 \", \"Unnamed: 3\": \"0.55 \", \"Unnamed: 4\": \"0.34 \"}]\n",
      "the json string is: [{\"Unnamed: 0\": NaN, \"Human \": \"mean \", \"Unnamed: 2\": \"std \", \"GPT-4 \": \"mean \", \"Unnamed: 4\": \"std \"}, {\"Unnamed: 0\": \"U \", \"Human \": \"0.15 \", \"Unnamed: 2\": \"0.36 \", \"GPT-4 \": \"0.14 \", \"Unnamed: 4\": \"0.35 \"}, {\"Unnamed: 0\": \"V \", \"Human \": \"0.31 \", \"Unnamed: 2\": \"0.37 \", \"GPT-4 \": \"0.35 \", \"Unnamed: 4\": \"0.35 \"}, {\"Unnamed: 0\": \"Z \", \"Human \": \"0.47 \", \"Unnamed: 2\": \"0.50 \", \"GPT-4 \": \"0.56 \", \"Unnamed: 4\": \"0.50 \"}]\n",
      "the json string is: [{\"Group \": \"Human U \", \"Occupations with highest exposure \": \"Interpreters and Translators \", \"% Exposure \": \"76.5 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Survey Researchers \", \"% Exposure \": \"75.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Poets, Lyricists and Creative Writers \", \"% Exposure \": \"68.8 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Animal Scientists \", \"% Exposure \": \"66.7 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Public Relations Specialists \", \"% Exposure \": \"66.7 \"}, {\"Group \": \"Human V \", \"Occupations with highest exposure \": \"Survey Researchers \", \"% Exposure \": \"84.4 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Writers and Authors \", \"% Exposure \": \"82.5 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Interpreters and Translators \", \"% Exposure \": \"82.4 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Public Relations Specialists \", \"% Exposure \": \"80.6 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Animal Scientists \", \"% Exposure \": \"77.8 \"}, {\"Group \": \"Human Z \", \"Occupations with highest exposure \": \"Mathematicians \", \"% Exposure \": \"100.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Tax Preparers \", \"% Exposure \": \"100.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Financial Quantitative Analysts \", \"% Exposure \": \"100.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Writers and Authors \", \"% Exposure \": \"100.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Web and Digital Interface Designers 100.0 Humans labeled 15 occupations as \\\"fully exposed.\\\" \", \"% Exposure \": NaN}, {\"Group \": \"Model U \", \"Occupations with highest exposure \": \"Mathematicians \", \"% Exposure \": \"100.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Correspondence Clerks \", \"% Exposure \": \"95.2 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Blockchain Engineers \", \"% Exposure \": \"94.1 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Court Reporters and Simultaneous Captioners \", \"% Exposure \": \"92.9 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Proofreaders and Copy Markers \", \"% Exposure \": \"90.9 \"}, {\"Group \": \"Model V \", \"Occupations with highest exposure \": \"Mathematicians \", \"% Exposure \": \"100.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Blockchain Engineers \", \"% Exposure \": \"97.1 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Court Reporters and Simultaneous Captioners \", \"% Exposure \": \"96.4 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Proofreaders and Copy Markers \", \"% Exposure \": \"95.5 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Correspondence Clerks \", \"% Exposure \": \"95.2 \"}, {\"Group \": \"Model Z Accountants and Auditors 100.0 News Analysts, Reporters, and Journalists 100.0 Legal Secretaries and Administrative Assistants 100.0 Clinical Data Managers 100.0 Climate Change Policy Analysts 100.0 The model labeled 86 occupations as \\\"fully exposed.\\\" \", \"Occupations with highest exposure \": NaN, \"% Exposure \": NaN}, {\"Group \": \"Highest variance \", \"Occupations with highest exposure \": \"Search Marketing Strategists \", \"% Exposure \": \"14.5 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Graphic Designers \", \"% Exposure \": \"13.4 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Investment Fund Managers \", \"% Exposure \": \"13.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Financial Managers \", \"% Exposure \": \"13.0 \"}, {\"Group \": NaN, \"Occupations with highest exposure \": \"Insurance Appraisers, Auto Damage \", \"% Exposure \": \"12.6 \"}]\n",
      "the json string is: [{\"Basic Skill\": \"All skill importance scores are normalized to be between 0 and 1. \", \"U (std err) \": NaN, \"(std err) V \": NaN, \"(std err) Z \": NaN}, {\"Basic Skill\": \"Constant \", \"U (std err) \": \"0.082*** (0.011) \", \"(std err) V \": \"-0.112*** (0.011) \", \"(std err) Z \": \"0.300*** (0.057) \"}, {\"Basic Skill\": \"Active Listening \", \"U (std err) \": \"0.128** (0.047) \", \"(std err) V \": \"0.214*** (0.043) \", \"(std err) Z \": \"0.449*** (0.027) \"}, {\"Basic Skill\": \"Mathematics \", \"U (std err) \": \"-0.127*** (0.026) \", \"(std err) V \": \"0.161*** (0.021) \", \"(std err) Z \": \"0.787*** (0.049) \"}, {\"Basic Skill\": \"Reading Comprehension \", \"U (std err) \": \"0.153*** (0.041) \", \"(std err) V \": \"0.470*** (0.037) \", \"(std err) Z \": \"-0.346*** (0.017) \"}, {\"Basic Skill\": \"Science \", \"U (std err) \": \"-0.114*** (0.014) \", \"(std err) V \": \"-0.230*** (0.012) \", \"(std err) Z \": \"-0.346*** (0.017) \"}, {\"Basic Skill\": \"Speaking \", \"U (std err) \": \"-0.028 (0.039) \", \"(std err) V \": \"0.133*** (0.033) \", \"(std err) Z \": \"0.294*** (0.042) \"}, {\"Basic Skill\": \"Writing \", \"U (std err) \": \"0.368*** (0.042) \", \"(std err) V \": \"0.467*** (0.037) \", \"(std err) Z \": \"0.566*** (0.047) \"}, {\"Basic Skill\": \"Active Learning \", \"U (std err) \": \"-0.157*** (0.027) \", \"(std err) V \": \"-0.065** (0.024) \", \"(std err) Z \": \"0.028 (0.032) \"}, {\"Basic Skill\": \"Critical Thinking \", \"U (std err) \": \"-0.264*** (0.036) \", \"(std err) V \": \"-0.196*** (0.033) \", \"(std err) Z \": \"-0.129** (0.042) \"}, {\"Basic Skill\": \"Learning Strategies \", \"U (std err) \": \"-0.072* (0.028) \", \"(std err) V \": \"-0.209*** (0.025) \", \"(std err) Z \": \"-0.346*** (0.034) \"}, {\"Basic Skill\": \"Monitoring \", \"U (std err) \": \"-0.067** (0.023) \", \"(std err) V \": \"-0.149*** 0.020) \", \"(std err) Z \": \"-0.232*** (0.026) \"}, {\"Basic Skill\": \"Programming \", \"U (std err) \": \"0.637*** (0.030) \", \"(std err) V \": \"0.623*** (0.022) \", \"(std err) Z \": \"0.609*** (0.024) \"}]\n",
      "the json string is: [{\"Job Zone \": NaN, \"Preparation Required \": NaN, \"Education Required \": NaN, \"Example Occupations \": NaN, \"Median Income \": NaN, \"Tot Emp (000s) \": NaN, \"H U \": NaN, \"M \": \"U\", \"H V \": NaN, \"MV \": NaN, \"H \": \"Z\", \"M .1\": \"Z \"}, {\"Job Zone \": \"1 \", \"Preparation Required \": \"None or little (0-3 months) \", \"Education Required \": \"High school diploma or GED (otional) \", \"Example Occupations \": \"Food preparation workers, dishwashers, floor sanders \", \"Median Income \": \"$30,230 \", \"Tot Emp (000s) \": \"13,100 \", \"H U \": \"0.03 \", \"M \": \"0.04 \", \"H V \": \"0.06 \", \"MV \": \"0.06 \", \"H \": \"0.09 \", \"M .1\": \"0.08 \"}, {\"Job Zone \": \"2 \", \"Preparation Required \": \"Some (3-12 months) \", \"Education Required \": \"High school diploma \", \"Example Occupations \": \"Orderlies, customer service representatives, tellers \", \"Median Income \": \"$38,215 \", \"Tot Emp (000s) \": \"73,962 \", \"H U \": \"0.07 \", \"M \": \"0.12 \", \"H V \": \"0.16 \", \"MV \": \"0.20 \", \"H \": \"0.24 \", \"M .1\": \"0.27 \"}, {\"Job Zone \": \"3 \", \"Preparation Required \": \"Medium (1-2 years) \", \"Education Required \": \"Vocational school, on-the-job training, or associate\\u2019s degree \", \"Example Occupations \": \"Electricians, barbers, medical assistants \", \"Median Income \": \"$54,815 \", \"Tot Emp (000s) \": \"37,881 \", \"H U \": \"0.11 \", \"M \": \"0.14 \", \"H V \": \"0.26 \", \"MV \": \"0.32 \", \"H \": \"0.41 \", \"M .1\": \"0.51 \"}, {\"Job Zone \": \"4 \", \"Preparation Required \": \"Considerable (2-4 years) \", \"Education Required \": \"Bachelor\\u2019s degree \", \"Example Occupations \": \"Database administrators, graphic designers, cost estimators \", \"Median Income \": \"$77,345 \", \"Tot Emp (000s) \": \"56,833 \", \"H U \": \"0.23 \", \"M \": \"0.18 \", \"H V \": \"0.47 \", \"MV \": \"0.51 \", \"H \": \"0.71 \", \"M .1\": \"0.85 \"}, {\"Job Zone \": \"5 \", \"Preparation Required \": \"Extensive (4+ years) \", \"Education Required \": \"Master\\u2019s degree or higher \", \"Example Occupations \": \"Pharmacists, lawyers, astronomers \", \"Median Income \": \"$81,980 \", \"Tot Emp (000s) \": \"21,221 \", \"H U \": \"0.23 \", \"M \": \"0.13 \", \"H V \": \"0.43 \", \"MV \": \"0.45 \", \"H \": \"0.63 \", \"M .1\": \"0.76 \"}]\n",
      "the json string is: [{\"On The Job Training Required \": \"None \", \"Median Income \": \"$77,440 \", \"Tot Emp (000s) \": \"90,776 \", \"HU \": \"0.20 \", \"MU \": \"0.16 \", \"HV \": \"0.42 \", \"MV \": \"0.46 \", \"HZ \": \"0.63 \", \"MZ \": \"0.76 \"}, {\"On The Job Training Required \": \"Apprenticeship \", \"Median Income \": \"$55,995 \", \"Tot Emp (000s) \": \"3,066 \", \"HU \": \"0.01 \", \"MU \": \"0.02 \", \"HV \": \"0.04 \", \"MV \": \"0.06 \", \"HZ \": \"0.07 \", \"MZ \": \"0.10 \"}, {\"On The Job Training Required \": \"Internship/residency \", \"Median Income \": \"$77,110 \", \"Tot Emp (000s) \": \"3,063 \", \"HU \": \"0.16 \", \"MU \": \"0.06 \", \"HV \": \"0.36 \", \"MV \": \"0.38 \", \"HZ \": \"0.55 \", \"MZ \": \"0.71 \"}, {\"On The Job Training Required \": \"Short-term on-the-job training \", \"Median Income \": \"$33,370 \", \"Tot Emp (000s) \": \"66,234 \", \"HU \": \"0.11 \", \"MU \": \"0.15 \", \"HV \": \"0.21 \", \"MV \": \"0.25 \", \"HZ \": \"0.32 \", \"MZ \": \"0.34 \"}, {\"On The Job Training Required \": \"Moderate-term on-the-job training \", \"Median Income \": \"$46,880 \", \"Tot Emp (000s) \": \"31,285 \", \"HU \": \"0.09 \", \"MU \": \"0.12 \", \"HV \": \"0.21 \", \"MV \": \"0.25 \", \"HZ \": \"0.32 \", \"MZ \": \"0.38 \"}, {\"On The Job Training Required \": \"Long-term on-the-job training \", \"Median Income \": \"$48,925 \", \"Tot Emp (000s) \": \"5,070 \", \"HU \": \"0.08 \", \"MU \": \"0.10 \", \"HV \": \"0.18 \", \"MV \": \"0.22 \", \"HZ \": \"0.28 \", \"MZ \": \"0.33 \"}]\n",
      "the json string is: [{\"Unnamed: 0\": \"GPT-4 Exposure Rating 1 \", \"Min \": \"0.00 \", \"25th Perc. \": \"0.13 \", \"Median \": \"0.34 \", \"75th Perc \": \"0.50 \", \"Max \": \"1.00 \", \"Mean \": \"0.33 \", \"Std. Dev. \": \"0.22 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"GPT-4 Exposure Rating 2 \", \"Min \": \"0.00 \", \"25th Perc. \": \"0.09 \", \"Median \": \"0.24 \", \"75th Perc \": \"0.40 \", \"Max \": \"0.98 \", \"Mean \": \"0.26 \", \"Std. Dev. \": \"0.20 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"Human Exposure Rating \", \"Min \": \"0.00 \", \"25th Perc. \": \"0.09 \", \"Median \": \"0.29 \", \"75th Perc \": \"0.47 \", \"Max \": \"0.84 \", \"Mean \": \"0.29 \", \"Std. Dev. \": \"0.21 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"Software (Webb) \", \"Min \": \"1.00 \", \"25th Perc. \": \"25.00 \", \"Median \": \"50.00 \", \"75th Perc \": \"75.00 \", \"Max \": \"100.00 \", \"Mean \": \"50.69 \", \"Std. Dev. \": \"30.05 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"Robot (Webb) \", \"Min \": \"1.00 \", \"25th Perc. \": \"22.00 \", \"Median \": \"52.00 \", \"75th Perc \": \"69.00 \", \"Max \": \"100.00 \", \"Mean \": \"48.61 \", \"Std. Dev. \": \"28.61 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"AI (Webb) \", \"Min \": \"1.00 \", \"25th Perc. \": \"28.00 \", \"Median \": \"55.00 \", \"75th Perc \": \"82.00 \", \"Max \": \"100.00 \", \"Mean \": \"54.53 \", \"Std. Dev. \": \"29.65 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"Suitability for Machine Learning \", \"Min \": \"2.60 \", \"25th Perc. \": \"2.84 \", \"Median \": \"2.95 \", \"75th Perc \": \"3.12 \", \"Max \": \"3.55 \", \"Mean \": \"2.99 \", \"Std. Dev. \": \"0.18 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"Normalized Routine Cognitive \", \"Min \": \"-3.05 \", \"25th Perc. \": \"-0.46 \", \"Median \": \"0.10 \", \"75th Perc \": \"0.63 \", \"Max \": \"3.42 \", \"Mean \": \"0.07 \", \"Std. Dev. \": \"0.86 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"Normalized Routine Manual \", \"Min \": \"-1.81 \", \"25th Perc. \": \"-0.81 \", \"Median \": \"-0.11 \", \"75th Perc \": \"0.73 \", \"Max \": \"2.96 \", \"Mean \": \"0.05 \", \"Std. Dev. \": \"1.01 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"AI Occupational Exposure Score \", \"Min \": \"1.42 \", \"25th Perc. \": \"3.09 \", \"Median \": \"3.56 \", \"75th Perc \": \"4.04 \", \"Max \": \"6.54 \", \"Mean \": \"3.56 \", \"Std. Dev. \": \"0.70 \", \"Count \": \"750 \"}, {\"Unnamed: 0\": \"Frey & Osborne Automation \", \"Min \": \"0.00 \", \"25th Perc. \": \"0.07 \", \"Median \": \"0.59 \", \"75th Perc \": \"0.88 \", \"Max \": \"0.99 \", \"Mean \": \"0.50 \", \"Std. Dev. \": \"0.38 \", \"Count \": \"681 \"}, {\"Unnamed: 0\": \"Log Avg. Salary \", \"Min \": \"10.13 \", \"25th Perc. \": \"10.67 \", \"Median \": \"11.00 \", \"75th Perc \": \"11.34 \", \"Max \": \"12.65 \", \"Mean \": \"11.02 \", \"Std. Dev. \": \"0.45 \", \"Count \": \"749 \"}]\n",
      "the json string is: [{\"Unnamed: 0\": NaN, \"GPT-4 Exposure Rating 1 \": \"(1) \", \"Unnamed: 2\": \"(2) \", \"GPT-4 Exposure Rating 2 \": \"(3) \", \"Unnamed: 4\": \"(4) \", \"Human Exposure Rating \": \"(5) \", \"Unnamed: 6\": \"(6) \"}, {\"Unnamed: 0\": \"Software (Webb) \", \"GPT-4 Exposure Rating 1 \": \"0.00113\\u21e4\\u21e4\\u21e4 (0.00031) \", \"Unnamed: 2\": \"0.00123\\u21e4\\u21e4\\u21e4 (0.00031) \", \"GPT-4 Exposure Rating 2 \": \"0.00111\\u21e4\\u21e4\\u21e4 (0.00031) \", \"Unnamed: 4\": \"0.00119\\u21e4\\u21e4\\u21e4 (0.00031) \", \"Human Exposure Rating \": \"0.00096\\u21e4\\u21e4\\u21e4 (0.00031) \", \"Unnamed: 6\": \"0.00101\\u21e4\\u21e4\\u21e4 (0.00031) \"}, {\"Unnamed: 0\": \"Robot (Webb) \", \"GPT-4 Exposure Rating 1 \": \"\\ue0220.00378\\u21e4\\u21e4\\u21e4 (0.00032) \", \"Unnamed: 2\": \"\\ue0220.00405\\u21e4\\u21e4\\u21e4 (0.00031) \", \"GPT-4 Exposure Rating 2 \": \"\\ue0220.00377\\u21e4\\u21e4\\u21e4 (0.00034) \", \"Unnamed: 4\": \"\\ue0220.00399\\u21e4\\u21e4\\u21e4 (0.00033) \", \"Human Exposure Rating \": \"\\ue0220.00371\\u21e4\\u21e4\\u21e4 (0.00029) \", \"Unnamed: 6\": \"\\ue0220.00383\\u21e4\\u21e4\\u21e4 (0.00028) \"}, {\"Unnamed: 0\": \"AI (Webb) \", \"GPT-4 Exposure Rating 1 \": \"0.00080\\u21e4\\u21e4\\u21e4 (0.00030) \", \"Unnamed: 2\": \"0.00090\\u21e4\\u21e4\\u21e4 (0.00029) \", \"GPT-4 Exposure Rating 2 \": \"0.00036 (0.00030) \", \"Unnamed: 4\": \"0.00045 (0.00030) \", \"Human Exposure Rating \": \"0.00067\\u21e4\\u21e4 (0.00030) \", \"Unnamed: 6\": \"0.00071\\u21e4\\u21e4 (0.00030) \"}, {\"Unnamed: 0\": \"Suitability for Machine Learning \", \"GPT-4 Exposure Rating 1 \": \"0.29522\\u21e4\\u21e4\\u21e4 (0.04503) \", \"Unnamed: 2\": \"0.26888\\u21e4\\u21e4\\u21e4 (0.04418) \", \"GPT-4 Exposure Rating 2 \": \"0.28468\\u21e4\\u21e4\\u21e4 (0.04404) \", \"Unnamed: 4\": \"0.26245\\u21e4\\u21e4\\u21e4 (0.04342) \", \"Human Exposure Rating \": \"0.19514\\u21e4\\u21e4\\u21e4 (0.03990) \", \"Unnamed: 6\": \"0.18373\\u21e4\\u21e4\\u21e4 (0.03886) \"}, {\"Unnamed: 0\": \"Normalized Routine Cognitive \", \"GPT-4 Exposure Rating 1 \": \"0.06601\\u21e4\\u21e4\\u21e4 (0.00886) \", \"Unnamed: 2\": \"0.06868\\u21e4\\u21e4\\u21e4 (0.00894) \", \"GPT-4 Exposure Rating 2 \": \"0.04743\\u21e4\\u21e4\\u21e4 (0.00872) \", \"Unnamed: 4\": \"0.05015\\u21e4\\u21e4\\u21e4 (0.00879) \", \"Human Exposure Rating \": \"0.03568\\u21e4\\u21e4\\u21e4 (0.00671) \", \"Unnamed: 6\": \"0.03659\\u21e4\\u21e4\\u21e4 (0.00669) \"}, {\"Unnamed: 0\": \"Normalized Routine Manual \", \"GPT-4 Exposure Rating 1 \": \"\\ue0220.11147\\u21e4\\u21e4\\u21e4 (0.00785) \", \"Unnamed: 2\": \"\\ue0220.11371\\u21e4\\u21e4\\u21e4 (0.00789) \", \"GPT-4 Exposure Rating 2 \": \"\\ue0220.09390\\u21e4\\u21e4\\u21e4 (0.00817) \", \"Unnamed: 4\": \"\\ue0220.09561\\u21e4\\u21e4\\u21e4 (0.00818) \", \"Human Exposure Rating \": \"\\ue0220.11045\\u21e4\\u21e4\\u21e4 (0.00741) \", \"Unnamed: 6\": \"\\ue0220.11152\\u21e4\\u21e4\\u21e4 (0.00744) \"}, {\"Unnamed: 0\": \"AI Occupational Exposure Score \", \"GPT-4 Exposure Rating 1 \": \"0.00993 (0.01107) \", \"Unnamed: 2\": \"0.02465\\u21e4\\u21e4 (0.01059) \", \"GPT-4 Exposure Rating 2 \": \"\\ue0220.01537 (0.01160) \", \"Unnamed: 4\": \"\\ue0220.00265 (0.01114) \", \"Human Exposure Rating \": \"0.00630 (0.00918) \", \"Unnamed: 6\": \"0.01252 (0.00845) \"}, {\"Unnamed: 0\": \"Frey & Osborne Automation \", \"GPT-4 Exposure Rating 1 \": \"\\ue0220.03024\\u21e4 (0.01835) \", \"Unnamed: 2\": \"\\ue0220.03950\\u21e4\\u21e4 (0.01841) \", \"GPT-4 Exposure Rating 2 \": \"\\ue0220.00364 (0.02007) \", \"Unnamed: 4\": \"\\ue0220.01217 (0.01972) \", \"Human Exposure Rating \": \"\\ue0220.03890\\u21e4\\u21e4 (0.01883) \", \"Unnamed: 6\": \"\\ue0220.04253\\u21e4\\u21e4 (0.01858) \"}, {\"Unnamed: 0\": \"Log Avg. Salary \", \"GPT-4 Exposure Rating 1 \": \"0.05804\\u21e4\\u21e4\\u21e4 (0.01870) \", \"Unnamed: 2\": NaN, \"GPT-4 Exposure Rating 2 \": \"0.04863\\u21e4\\u21e4\\u21e4 (0.01860) \", \"Unnamed: 4\": NaN, \"Human Exposure Rating \": \"0.02531 (0.01727) \", \"Unnamed: 6\": NaN}, {\"Unnamed: 0\": \"Constant \", \"GPT-4 Exposure Rating 1 \": \"\\ue0221.12937\\u21e4\\u21e4\\u21e4 (0.26859) \", \"Unnamed: 2\": \"\\ue0220.45743\\u21e4\\u21e4\\u21e4 (0.15327) \", \"GPT-4 Exposure Rating 2 \": \"\\ue0220.96117\\u21e4\\u21e4\\u21e4 (0.26365) \", \"Unnamed: 4\": \"\\ue0220.39935\\u21e4\\u21e4\\u21e4 (0.15017) \", \"Human Exposure Rating \": \"\\ue0220.47078\\u21e4 (0.24684) \", \"Unnamed: 6\": \"\\ue0220.17706 (0.13256) \"}, {\"Unnamed: 0\": \"N \", \"GPT-4 Exposure Rating 1 \": \"680.00000 \", \"Unnamed: 2\": \"681.00000 \", \"GPT-4 Exposure Rating 2 \": \"680.00000 \", \"Unnamed: 4\": \"681.00000 \", \"Human Exposure Rating \": \"680.00000 \", \"Unnamed: 6\": \"681.00000 \"}, {\"Unnamed: 0\": \"'2 \", \"GPT-4 Exposure Rating 1 \": \"0.68741 \", \"Unnamed: 2\": \"0.68212 \", \"GPT-4 Exposure Rating 2 \": \"0.60737 \", \"Unnamed: 4\": \"0.60198 \", \"Human Exposure Rating \": \"0.71213 \", \"Unnamed: 6\": \"0.71126 \"}]\n"
     ]
    }
   ],
   "source": [
    "# Adobe output zip file path\n",
    "input_pdf = '../data/raw/GPTsareGPTs.pdf'\n",
    "output_zip_path = '../data/processed/adobe_result/sdk.zip'\n",
    "output_zipextract_folder = '../data/processed/adobe_result/'\n",
    "# Run adobe API\n",
    "adobeLoader(input_pdf, output_zip_path, client_id= client_id, client_secret=client_secret)\n",
    "# unzip adobe output zipfile, extract text and table from adobe output zip file\n",
    "df, json_strings = extract_text_from_file_adobe(output_zip_path, output_zipextract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93f5db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly model capabilities are progressing – consider the jump in exam performance between GPT-3.5 and GPT-4 (OpenAI, 2023b). \n",
      "Our study is motivated less by the progress of these models alone though, and more by the breadth, scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used for custom search applications, and LLMs can perform tasks such as summarization and classification where the context may be largely contained in the prompt. \n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding the evolving landscape of language models and their associated technologies, we propose a new rubric for assessing LLM capabilities and their potential eﬀects on jobs. This rubric (A.1) measures the overall exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning (Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We define exposure as a proxy for potential economic impact without distinguishing between labor-augmenting or labor-displacing eﬀects. We employ human annotators and GPT-4 itself as a classifier to apply this rubric to occupational data in the U.S. economy, primarily sourced from the O*NET database.12 \n",
      "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classifications, using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement \n",
      "1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen et al., 2022) \n",
      "2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners (OpenAI, 2023b). \n"
     ]
    }
   ],
   "source": [
    "print(df['text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcfda119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GPTs are GPTs: An Early Look at the Labor Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Figure 1: Taken directly from GPT-4 Technical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>levels in GPT-4 responses and between human an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>policymakers to predict and regulate. As with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Furthermore, a positive feedback loop may emer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                               text\n",
       "0            0  GPTs are GPTs: An Early Look at the Labor Mark...\n",
       "1            1  Figure 1: Taken directly from GPT-4 Technical ...\n",
       "2            2  levels in GPT-4 responses and between human an...\n",
       "3            3  policymakers to predict and regulate. As with ...\n",
       "4            4  Furthermore, a positive feedback loop may emer..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059012b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "table-parsing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
